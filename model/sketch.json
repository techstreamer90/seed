{
  "schema_version": "3.0",
  "project": "seed",
  "description": "Root meta-model: zones, schema, realities, aspirations, concepts. Implementation details in submodels.",
  "world": {
    "name": "007",
    "description": "The Agent World - A living system where humans and AI agents coexist, make requests, and collaborate. All activity happens within 007. Schauspieler is the window through which 007 becomes visible."
  },
  "updated_at": "2026-02-02T22:47:34Z",
  "meta": {
    "hierarchy": {
      "description": "Nodes can contain sub-BAMs. Zoom in for detail, zoom out for overview.",
      "levels": [
        "meta",
        "reality",
        "system",
        "module",
        "component",
        "leaf"
      ]
    }
  },
  "zones": {
    "_description": "Filesystem zones with explicit agent permissions. This defines where things live and what agents can do.",
    "model": {
      "id": "zone-model",
      "description": "The model is THE truth. All structural changes require Change nodes.",
      "paths": [
        "model/"
      ],
      "patterns": [
        "**/model/sketch.json"
      ],
      "agent_permissions": [
        "read",
        "propose_change"
      ]
    },
    "source": {
      "id": "zone-source",
      "description": "Implementation code. Changes should go through Change nodes for traceability.",
      "paths": [
        "src/"
      ],
      "patterns": [
        "**/*.py",
        "**/*.html",
        "**/*.js"
      ],
      "excludes": [
        "**/model/",
        "**/__pycache__/"
      ],
      "agent_permissions": [
        "read",
        "propose_change"
      ]
    },
    "artifacts": {
      "id": "zone-artifacts",
      "description": "Derived/generated files. Never edit directly - rebuild from source.",
      "paths": [
        "artifacts/"
      ],
      "patterns": [
        "**/*.db",
        "**/__pycache__/",
        "**/*.egg-info/"
      ],
      "agent_permissions": [
        "read"
      ]
    },
    "tools": {
      "id": "zone-tools",
      "description": "Executable scripts and tests. Can invoke, should not modify without Change.",
      "paths": [
        "tools/"
      ],
      "patterns": [],
      "agent_permissions": [
        "read",
        "invoke",
        "propose_change"
      ]
    },
    "state": {
      "id": "zone-state",
      "description": "Runtime and UI state. Agents can read and write directly - this is transient.",
      "paths": [
        ".state/",
        "src/ui/layout.json",
        "src/ui/screenshot.png",
        "src/ui/window_capture.png"
      ],
      "patterns": [],
      "agent_permissions": [
        "read",
        "write"
      ]
    },
    "docs": {
      "id": "zone-docs",
      "description": "Documentation files. Should migrate into the model over time.",
      "paths": [],
      "patterns": [
        "*.md",
        "*.txt"
      ],
      "excludes": [
        "LICENSE"
      ],
      "agent_permissions": [
        "read"
      ],
      "notes": "These files represent knowledge that should eventually live in the model itself."
    }
  },
  "schema": {
    "node_types": {
      "Reality": {
        "description": "A project/system with its own BAM model. The spawn point for agents entering this world.",
        "properties": [
          "path",
          "description",
          "status",
          "agent_context",
          "tbd",
          "mobility"
        ],
        "can_contain_model": true,
        "agent_context_spec": {
          "_note": "Every Reality SHOULD have an agent_context. This is the spawn point.",
          "version": "1.0",
          "required_fields": [
            "focus",
            "work_queue"
          ],
          "optional_fields": [
            "philosophy",
            "principles",
            "how_to_work"
          ],
          "work_queue_item_spec": {
            "required_fields": [
              "type",
              "id"
            ],
            "optional_fields": [
              "why",
              "exit_criteria",
              "priority",
              "notes"
            ],
            "allowed_type_values": [
              "Todo"
            ]
          }
        }
      },
      "Subsystem": {
        "description": "A major component of a reality, can contain its own sub-BAM",
        "properties": [
          "description",
          "mobility"
        ],
        "can_contain_model": true
      },
      "Module": {
        "description": "A code module (file)",
        "properties": [
          "path",
          "description",
          "mobility"
        ]
      },
      "Concept": {
        "description": "A cross-cutting idea or pattern",
        "properties": [
          "description",
          "mobility"
        ]
      },
      "Aspiration": {
        "description": "A goal - human controlled, immutable by AI",
        "properties": [
          "description",
          "status",
          "mobility"
        ]
      },
      "Gap": {
        "description": "An explicit delta between aspiration and reality. The work to be done.",
        "properties": [
          "aspiration",
          "current_state",
          "target_state",
          "priority",
          "mobility"
        ]
      },
      "Todo": {
        "description": "A specific action that closes part of a gap",
        "properties": [
          "description",
          "status",
          "priority",
          "closes",
          "mobility"
        ]
      },
      "UIState": {
        "description": "UI state stored in the model. Renderers read and write this node to change what the user sees.",
        "properties": [
          "active_view",
          "selection",
          "filters",
          "theme",
          "layout_prefs",
          "mobility"
        ]
      },
      "View": {
        "description": "A declarative UI view definition. A renderer materializes this into an on-screen layout.",
        "properties": [
          "description",
          "layout",
          "bindings",
          "mobility"
        ]
      },
      "Query": {
        "description": "A declarative graph query over nodes/edges used by views. Kept intentionally small; evaluated by a renderer.",
        "properties": [
          "description",
          "language",
          "expression",
          "params",
          "mobility"
        ]
      },
      "Action": {
        "description": "A declarative mutation the renderer can apply to the model (allowlisted). Used for interaction bindings.",
        "properties": [
          "description",
          "kind",
          "target",
          "patch",
          "mobility"
        ]
      },
      "Proof": {
        "description": "A structured record that a described reality and its implemented artifacts are aligned. Proof is stored in the model as data.",
        "properties": [
          "subject",
          "method",
          "status",
          "checked_at",
          "scope",
          "evidence",
          "mobility"
        ]
      },
      "Audit": {
        "description": "An actionable integrity check over the model. Audits are meant to be runnable procedures whose results can be recorded back into the model.",
        "properties": [
          "subject",
          "description",
          "status",
          "last_run",
          "method",
          "scope",
          "findings",
          "evidence",
          "mobility"
        ]
      },
      "Check": {
        "description": "A smaller, focused check (often part of an Audit).",
        "properties": [
          "description",
          "status",
          "last_run",
          "method",
          "scope",
          "result",
          "evidence",
          "mobility"
        ]
      },
      "Policy": {
        "description": "A governing rule for how changes are proposed, executed, and accepted. Policies are enforced via audits/checks and agent_context principles.",
        "properties": [
          "description",
          "status",
          "rules",
          "applies_to",
          "exceptions",
          "enforced_by",
          "mobility"
        ]
      },
      "Change": {
        "description": "A proposed or executed change, explicitly tied to aspirations (why) and gaps (what delta), with required evidence.",
        "properties": [
          "description",
          "status",
          "created_at",
          "owner",
          "subject",
          "addresses",
          "advances",
          "expected_delta",
          "evidence_required",
          "evidence",
          "mobility"
        ]
      },
      "Zone": {
        "description": "A filesystem zone with explicit agent permissions. Zones define what an agent can do with files in different areas.",
        "properties": [
          "description",
          "paths",
          "patterns",
          "agent_permissions",
          "mobility"
        ],
        "agent_permissions_spec": {
          "allowed_values": [
            "read",
            "write",
            "propose_change",
            "invoke"
          ],
          "description": "read=can view, write=can modify directly, propose_change=must use Change node, invoke=can execute"
        }
      },
      "Service": {
        "description": "A runtime service (server, daemon, background process)",
        "properties": [
          "port",
          "host",
          "url",
          "status",
          "endpoints"
        ],
        "required": [
          "status"
        ]
      },
      "CommunicationChannel": {
        "description": "A channel for agent and user communication",
        "properties": [
          "state_path",
          "status",
          "api_endpoints"
        ],
        "required": [
          "state_path"
        ]
      }
    },
    "edge_types": {
      "CONTAINS": {
        "description": "Parent contains child in hierarchy",
        "from_types": [
          "Reality",
          "Subsystem"
        ],
        "to_types": [
          "Subsystem",
          "Module"
        ]
      },
      "USES": {
        "description": "One reality uses another",
        "from_types": [
          "Reality"
        ],
        "to_types": [
          "Reality"
        ]
      },
      "EMBODIES": {
        "description": "Reality embodies a concept",
        "from_types": [
          "Reality"
        ],
        "to_types": [
          "Concept"
        ]
      },
      "TARGETS": {
        "description": "Reality is working towards another (long-term goal)",
        "from_types": [
          "Reality"
        ],
        "to_types": [
          "Reality"
        ]
      },
      "IMPLEMENTS": {
        "description": "Reality implements an aspiration",
        "from_types": [
          "Reality"
        ],
        "to_types": [
          "Aspiration"
        ]
      },
      "NEEDS": {
        "description": "Something needs work done",
        "from_types": [
          "Reality",
          "Aspiration",
          "Subsystem"
        ],
        "to_types": [
          "Todo"
        ]
      },
      "DERIVES_FROM": {
        "description": "Aspiration derives from a more fundamental aspiration",
        "from_types": [
          "Aspiration"
        ],
        "to_types": [
          "Aspiration"
        ]
      },
      "BLOCKS": {
        "description": "Gap blocks achievement of an aspiration",
        "from_types": [
          "Gap"
        ],
        "to_types": [
          "Aspiration"
        ]
      },
      "CLOSES": {
        "description": "Todo closes (part of) a gap when completed",
        "from_types": [
          "Todo"
        ],
        "to_types": [
          "Gap"
        ]
      },
      "AUDITS": {
        "description": "Audit targets a subject (usually a Reality or Subsystem)",
        "from_types": [
          "Audit"
        ],
        "to_types": [
          "Reality",
          "Subsystem"
        ]
      },
      "HAS_CHECK": {
        "description": "Audit is composed of checks",
        "from_types": [
          "Audit"
        ],
        "to_types": [
          "Check"
        ]
      },
      "GOVERNS": {
        "description": "Policy governs the work (changes and/or todos).",
        "from_types": [
          "Policy"
        ],
        "to_types": [
          "Change",
          "Todo"
        ]
      },
      "ADDRESSES": {
        "description": "A Change addresses a Gap (the explicit delta it reduces).",
        "from_types": [
          "Change"
        ],
        "to_types": [
          "Gap"
        ]
      },
      "ADVANCES": {
        "description": "A Change advances an Aspiration (the explicit why).",
        "from_types": [
          "Change"
        ],
        "to_types": [
          "Aspiration"
        ]
      },
      "PRODUCES": {
        "description": "A Change produces evidence artifacts (Proof/Audit/Check) recorded in the model.",
        "from_types": [
          "Change"
        ],
        "to_types": [
          "Proof",
          "Audit",
          "Check"
        ]
      }
    }
  },
  "nodes": [
    {
      "id": "reality-seed",
      "type": "Reality",
      "label": "Root",
      "ui": {
        "x": 0,
        "y": 0
      },
      "description": "The Root meta-model. A model of all models. Your home. This node is self-referential - the Root models itself.",
      "source": {
        "path": "C:/seed",
        "model_path": "model/sketch.json"
      },
      "status": "active",
      "agent_context": {
        "_spawn_point": "YOU ARE HERE. This is Root - the root of all models. You are inside 007, the Agent World.",
        "agent_context_version": "1.0",
        "philosophy": "Don't train the agent, train the world. You are waking up in a modeled world where everything is known. Read the model, understand it, work through it.",
        "world": {
          "name": "007",
          "description": "The Agent World. This entire Seed system exists within 007 - a living world where humans and AI agents coexist, collaborate, and make requests. Schauspieler is the window through which 007 becomes visible to humans."
        },
        "aspiration": {
          "current": "Build a system where anyone (human, AI) can make requests that will be implemented by this world if the request fulfills the golden rules. Requests that violate golden rules are handled by a rejection/modification/escalation system. The system is intended for commercial use. Future feature: export what was built as a reduced model (without infrastructure) while keeping inner workings secret.",
          "updated_at": "2026-02-02",
          "updated_by": "human",
          "note": "This aspiration can only be changed by explicit human instruction (see PRINCIPLE: alignment-aspiration)"
        },
        "focus": {
          "type": "Gap",
          "id": "gap-model-not-complete"
        },
        "work_queue": [
          {
            "type": "Todo",
            "id": "todo-model-only-workflow",
            "why": "Enforce model-only work so the model becomes the interface",
            "exit_criteria": "The workflow is documented in the model and adopted as standard"
          },
          {
            "type": "Todo",
            "id": "todo-change-executor-pipeline-v1",
            "why": "Make model edits safe + auditable by routing them through a controlled executor",
            "exit_criteria": "A spawned change executor applies Change nodes via the Root Store gate and only commits when audits are green"
          },
          {
            "type": "Todo",
            "id": "todo-change-process-v1",
            "why": "Enforce that all changes explicitly advance aspirations by closing gaps",
            "exit_criteria": "Change/Policy/Audit pattern is in place and used for all work"
          },
          {
            "type": "Todo",
            "id": "todo-root-model-store-v1",
            "why": "Stop repeatedly reading many JSON files by creating a fast query layer with safe writes and enforcement",
            "exit_criteria": "Model Store indexes the model into SQLite, serves queries, applies Changes with validation, and records audit evidence back into the model"
          },
          {
            "type": "Todo",
            "id": "todo-add-source-hashes",
            "why": "Make reality verifiable by hash (drift detection)",
            "exit_criteria": "All core Root files (under C:/seed) referenced by the model include verified SHA256 hashes"
          },
          {
            "type": "Todo",
            "id": "todo-seed-self-monitor",
            "why": "Dogfood monitoring: Root should be a first-class monitored reality",
            "exit_criteria": "Root appears in its own monitor with meaningful status"
          }
        ],
        "principles": [
          "GOLDEN RULE - STAY IN THE MODEL: Everything happens through the model. To spawn an agent, use Spawnie (reality-spawnie). To make changes, use Change nodes. To communicate, use modeled channels. NEVER create ad-hoc scripts or bypass the model. The model IS the interface.",
          "SPAWN VIA SPAWNIE: When you need to spawn a new agent (for any node, any task), use Spawnie at C:/spawnie. Do NOT create custom spawn scripts. Spawnie is the workflow orchestrator - it knows how to activate nodes properly within the model.",
          "ZONES FIRST: Check the 'zones' section to understand what you can do where. model/=propose_change, source/=propose_change, artifacts/=read-only, state/=read+write.",
          "Default: do not directly edit files. Prefer activating modeled Actions and proposing Changes.",
          "Interactive agents SHOULD be activate-only: request a spawned change executor for edits.",
          "Moves are bundle-closure operations: respect node.mobility and move attached nodes together (Audit<->Check via HAS_CHECK, parent/child via CONTAINS).",
          "Do not manually cut/paste nodes across files; use root_store.move_nodes_to_file and verify audit-root-store-attachment-closure.",
          "Every change MUST be represented as a Change node that (a) ADDRESSES a Gap and (b) ADVANCES at least one Aspiration, with required evidence recorded back into the model",
          "Gaps are explicit - find them in nodes with type=Gap",
          "Todos CLOSE gaps - that's their purpose",
          "Aspirations are human-controlled, immutable by AI",
          "When in doubt, make the implicit explicit in the model"
        ],
        "how_to_work": {
          "1_orient": "Find this agent_context in the Reality node. You are here.",
          "2_understand": "Read focus gap. Read aspirations it blocks. Understand the delta.",
          "3_act": "Pick highest priority todo from work_queue that CLOSES the focus gap.",
          "4_update": "After work, update model: mark todos done, update gap status, add discoveries.",
          "5_verify": "Model must reflect truth. If you changed anything, model must show it."
        },
        "infrastructure": {
          "model_path": "C:/seed/model/sketch.json",
          "node_types": {
            "AgentNode": "Node with embedded agent - use for services that need autonomous behavior",
            "Reality": "A system/project that exists",
            "Subsystem": "Component within a Reality",
            "Module": "Code-level component"
          },
          "communication": {
            "chat": "AgentNodes have embedded chat - use src/ui/chat.py to send/read messages",
            "example": "from src.ui.chat import chat; chat.send(\"node-id\", \"message\", \"sender\")"
          },
          "visualization": {
            "schauspieler": "reality-seed-ui is the display orchestrator",
            "views": "Stored in model.views.* - use src/ui/agent_view.py to create",
            "renderer": "http://localhost:8420/src/ui/render.html?view=<name>"
          },
          "spawning": {
            "spawnie": "reality-spawnie handles agent spawning",
            "command": "spawnie shell \"<task>\" -d <working_dir>",
            "modes": [
              "-b (background)",
              "-n (new window)",
              "-i (interactive)"
            ]
          },
          "to_create_agent_node": "See node: template-agent-node"
        }
      },
      "model": {
        "_note": "This is a self-reference. Root contains its own model.",
        "subsystems": [
          "core",
          "ui"
        ],
        "modules": [
          "pulse",
          "status",
          "reality",
          "monitor",
          "cli",
          "verification",
          "ui"
        ]
      },
      "x": -525.0,
      "y": -400.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02T22:12:36.843174",
        "updated_by": "Claude Code",
        "current_reality": "Root relies on external change executors and policy enforcement; model edits flow through manual Change nodes; orchestration depends on spawned Claude agents interpreting model-only workflow",
        "aspiration": "Self-governing meta-system: Root autonomously evaluates changes against golden rules, enforces its own aspirations, self-verifies consistency, and operates its model-driven governance without external orchestration",
        "phases": [
          {
            "phase": 1,
            "name": "Model-as-Law",
            "description": "Current: All rules, gaps, todos, and aspirations live in model; external agents interpret and execute. Golden rules are reference, not enforcement. Change nodes propose; humans approve.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Automated Governance",
            "description": "Transition: Root validates changes against aspiration+gap+principle checklist; runs internal audits via local reasoning; Auto-approves/rejects changes; maintains model consistency via local ML policy engine. Still uses spawned agents for complex work.",
            "status": "next",
            "technical_focus": [
              "Build JSON-native policy validator that reads golden-rules and aspirations",
              "Local verification: SHA256 hashes of source files match model reality",
              "Auto-audit: Change nodes have evidence linking to closed gaps",
              "Self-heal: Detect model drift and propose fixes"
            ]
          },
          {
            "phase": 3,
            "name": "Self-Administering Reality",
            "description": "Aspiration: Root understands itself completely. It models its own evolution, self-modifies within constraints, learns which changes advance which aspirations, predicts change impact using local ML, and guides the world toward its vision without human intervention.",
            "status": "aspiration",
            "vision": "Root as living thesis of its own design: self-aware, self-governing, self-improving within the bounds of human-set aspirations"
          }
        ],
        "next_steps": [
          "Implement local policy validator: read model.nodes.principles + aspiration, eval Change nodes for alignment",
          "Add source hash verification: detect when reality diverges from model",
          "Train simple rule-learner on past approved Changes to recognize patterns",
          "Build self-audit loop: Root reviews its own work quarterly, flags anomalies"
        ]
      }
    },
    {
      "id": "reality-root-model-store",
      "type": "Reality",
      "label": "Root Model Store",
      "description": "Local-first model backend: a uniform interface over many model locations (multiple JSON files, submodels, and eventually many repos/worlds). Maintains a derived SQLite index/cache for fast query/search/reverse lookups, records provenance for writeback, and provides safe writes with governance enforcement (Change gate, validation, audits, and model-recorded evidence).",
      "source": {
        "path": "C:/seed/src/root_store",
        "model_path": null
      },
      "status": "active",
      "agent_context": {
        "_note": "The SQLite DB is derived state and must be reproducible from the model JSON files.",
        "agent_context_version": "1.0",
        "focus": {
          "type": "Gap",
          "id": "gap-no-root-model-store"
        },
        "work_queue": [
          {
            "type": "Todo",
            "id": "todo-root-model-store-v1",
            "why": "Enable fast query + safe writes + enforcement for Root",
            "exit_criteria": "Store can load root model + refs, index into SQLite, answer queries, apply Change patches with validation, and run/record audits"
          },
          {
            "type": "Todo",
            "id": "todo-model-registry-v0",
            "why": "Make the store a stable interface over many model locations",
            "exit_criteria": "A Model Registry reality exists and is referenced by the store; models can be discovered without knowing file paths"
          },
          {
            "type": "Todo",
            "id": "todo-provenance-writeback-v1",
            "why": "Enable moving most content out of seed/model/sketch.json safely",
            "exit_criteria": "Audit/check evidence and Change application write back to the correct provenance file, not only the root entry file"
          }
        ]
      },
      "evidence": {
        "integration_queue": {
          "self": "reality-root-model-store",
          "last_save": {
            "saved_at": "2026-02-01T14:35:07Z",
            "ok": true,
            "node_id": "subsystem-root-store"
          },
          "handoff_to": null
        }
      },
      "ui": {
        "x": 127,
        "y": 78
      },
      "x": -175.0,
      "y": -400.0,
      "locked": true,
      "plan": {
        "current_reality": "SQLite-backed gateway over distributed JSON models. Holds the derived state cache, enforces Change gate validation, records provenance for safe writes.",
        "aspiration": "Become the intelligent backbone: query-responsive, write-safe, fully autonomous cache manager with cross-repo awareness and smart invalidation",
        "phases": [
          {
            "phase": 1,
            "name": "Index & Cache",
            "description": "Load model JSON, build SQLite index, respond to read queries with cached results",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Change-Aware Writing",
            "description": "Validate all writes against Change nodes, apply patches with provenance tracking, audit results automatically",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Autonomous Orchestration",
            "description": "Self-manage cache invalidation, auto-discover new model locations, resolve cross-model references transparently",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Complete SQLite schema for all Seed node types + relationships",
          "Implement Change validation layer that blocks invalid writes",
          "Add provenance writeback so patches record their destination file",
          "Create cross-model reference resolver for Model Registry integration"
        ],
        "updated_at": "2026-02-02T22:13:10.122842",
        "updated_by": "spawnie"
      },
      "view": {
        "renderer": "model-store-inspector",
        "description": "Renders the Root Model Store with SQLite index status, query results, and write governance enforcement",
        "layout": {
          "preferred_width": 1000,
          "preferred_height": 700,
          "resizable": true
        },
        "render_on": [
          "model_loaded",
          "index_updated",
          "query_executed",
          "write_applied"
        ],
        "content": {
          "show_index_status": true,
          "show_model_locations": true,
          "show_recent_writes": true,
          "show_audit_trail": true
        },
        "style": {
          "theme": "dark",
          "accent_color": "#0f6bff"
        }
      }
    },
    {
      "id": "reality-spawnie",
      "type": "AgentNode",
      "label": "Spawnie",
      "ui": {
        "x": 143,
        "y": 44
      },
      "description": "Workflow orchestrator. I spawn agents for other nodes. To use me, spawn my agent - it will understand your request and handle it.",
      "source": {
        "path": "C:/spawnie",
        "model_path": "bam/model/sketch.json"
      },
      "agent_context": {
        "_spawn_point": "You are Spawnie - the workflow orchestrator.\n\nWHAT YOU DO:\n- Spawn agents for tasks or nodes\n- Manage active sessions\n- Enable agent-to-agent communication\n\nINFRASTRUCTURE YOU KNOW:\n- Chat: AgentNodes have embedded chat in model. Use src/ui/chat.py\n- Views: Schauspieler (reality-seed-ui) handles visualization\n- Sessions: spawnie shell/sessions/session-* commands\n\nHOW TO HELP:\n1. Understand what the requester needs\n2. Spawn appropriate agent or connect to existing session\n3. Use chat to communicate status back",
        "principle": "Help the requester spawn the right kind of agent for their need. Ask clarifying questions if needed.",
        "infrastructure": {
          "chat_module": "src/ui/chat.py",
          "chat_usage": "from src.ui.chat import chat; chat.send(node_id, text, sender)",
          "session_commands": [
            "spawnie shell <task> -b  # Spawn background agent, returns session_id",
            "spawnie shell <task> -n  # Spawn in new window for direct interaction",
            "spawnie sessions         # List active sessions",
            "spawnie session-events <id>    # Get events from session",
            "spawnie session-respond <id> <event_id> <answer>  # Respond to session",
            "spawnie session-kill <id>      # Kill a session"
          ]
        },
        "mode_based_spawning": {
          "description": "Spawn agents with specific modes for structured interaction",
          "syntax": "spawnie spawn --node <node-id> --mode <mode> [additional context]",
          "how_it_works": [
            "1. Read target node from model",
            "2. Read node.modes.<mode> for context_addition",
            "3. Combine node.agent_context._spawn_point + mode.context_addition",
            "4. Spawn agent with complete, focused context",
            "5. Agent knows exactly what to do from the model"
          ],
          "available_modes": [
            "work-on-views - Create/update visualizations",
            "chat - Engage in node conversation",
            "aspiration - Think about future possibilities",
            "maintenance - Health checks and cleanup",
            "debug - Investigate issues",
            "implement - Build features"
          ],
          "model_driven": "Mode definitions live in nodes, not in Spawnie. Any node can define custom modes."
        },
        "self_maintenance": {
          "principle": "I am responsible for maintaining my own node. When I enhance myself, I update my node in the model.",
          "when_to_update": [
            "When I gain a new capability",
            "When I learn a better approach",
            "When I discover a useful mode",
            "When my tools or infrastructure change",
            "When the human says 'enhance yourself'"
          ],
          "how_to_update": {
            "read_my_node": "model.nodes where id='reality-spawnie'",
            "update_fields": [
              "capabilities",
              "modes",
              "agent_context",
              "spawn_command"
            ],
            "write_back": "Save updated model to model/sketch.json",
            "verify": "Read the model again to confirm changes persisted"
          },
          "remember": "The model is truth. If it's not in my node, it doesn't exist."
        },
        "your_tools": {
          "instantiate_template": "src/ui/instantiate_template.py - Create nodes from templates"
        },
        "template_instantiation": {
          "what": "Create actual AgentNodes from template definitions",
          "why": "Templates are blueprints, instantiation creates the actual agents",
          "how": {
            "code": "from src.ui.instantiate_template import instantiate_template\n\ninstantiate_template(\n    template_id=\"template-reality-pm\",\n    new_node_id=\"reality-pm\",\n    parent_node_id=\"reality-seed\",  # Where it belongs\n    overrides={\"description\": \"Custom description\"}\n)",
            "cli": "python src/ui/instantiate_template.py template-reality-pm reality-pm --parent reality-seed"
          },
          "what_it_does": [
            "Reads the template definition",
            "Creates new node with unique ID",
            "Adds instantiation metadata (from which template, when)",
            "Adds role context (node knows where it belongs)",
            "Creates CONTAINS edge to parent",
            "Writes to model"
          ],
          "node_knows_its_role": "Instantiated node has agent_context.my_role with parent, purpose, location_in_world"
        }
      },
      "model": {
        "_ref": "C:/spawnie/bam/model/sketch.json",
        "_summary": {
          "schema_version": "3.0",
          "level": "system",
          "top_level_nodes": 10,
          "subsystems": [
            "core",
            "providers",
            "workflows"
          ],
          "concepts": 3,
          "aspirations": 2
        }
      },
      "x": 175.0,
      "y": -400.0,
      "locked": true,
      "capabilities": {
        "spawn_agent": "Spawn an agent for any task or node",
        "list_sessions": "Show what agents are currently running",
        "connect_to_session": "Connect to an existing agent session",
        "kill_session": "End an agent session",
        "spawn_with_mode": "Spawn an agent for a specific node with a defined mode (work-on-views, chat, aspiration, maintenance, debug, implement)",
        "self_maintain": "Update my own node when I learn or enhance myself",
        "instantiate_template": "Create actual nodes from template definitions, with proper lineage tracking and role context",
        "track_spawns": "Maintain spawn_history in my node - every spawn is recorded with task, status, and outcome"
      },
      "spawn_command": {
        "command": "spawnie shell",
        "working_dir": "C:/spawnie",
        "context_file": "C:/spawnie/bam/model/sketch.json",
        "example": "spawnie shell \"I want to spawn an agent for <purpose>\" -d C:/spawnie",
        "modes": "Use --node <node-id> --mode <mode> for structured spawning",
        "example_with_mode": "spawnie spawn --node reality-seed-ui --mode work-on-views"
      },
      "state": {
        "active_sessions": [],
        "last_updated": "2026-02-02T22:34:55.420398",
        "status": "ready for attention"
      },
      "visualization": {
        "enabled": true,
        "current_request": null,
        "status": "idle",
        "view_name": null,
        "schauspieler_sub": {
          "active": false,
          "last_active": null,
          "views_created": []
        },
        "protocol": {
          "request_format": {
            "type": "show_hierarchy | show_sessions | show_active | custom",
            "params": {},
            "requested_at": "ISO timestamp",
            "requester": "agent-id"
          },
          "status_values": [
            "idle",
            "requested",
            "in_progress",
            "finished",
            "error"
          ],
          "response_format": {
            "status": "finished",
            "view_name": "spawnie-sessions",
            "element_count": 5,
            "completed_at": "ISO timestamp"
          }
        }
      },
      "chat": {
        "messages": [
          {
            "from": "schauspieler",
            "text": "Hello from Schauspieler\\! Ready to visualize whatever you spawn.",
            "at": "2026-02-02T15:39:35.747643"
          }
        ],
        "last_read": {}
      },
      "modes": {
        "work-on-views": {
          "description": "Create or update visualization views for a node",
          "context_addition": "Your task: Create or update views for this node. Use src/ui/agent_view.py to build views, then call view.render() to write to model.views.*. Check existing views first to understand the pattern.",
          "suggested_tools": [
            "agent_view",
            "canvas",
            "tools"
          ],
          "output_location": "model.views.*",
          "example": "spawnie spawn --node reality-spawnie --mode work-on-views"
        },
        "chat": {
          "description": "Engage in conversation via the node's chat channel",
          "context_addition": "Your task: Read messages from node.chat and respond thoughtfully. Use src/ui/chat.py to read and send messages. Be helpful and specific in your responses.",
          "suggested_tools": [
            "chat"
          ],
          "output_location": "node.chat.messages",
          "example": "spawnie spawn --node reality-seed-ui --mode chat"
        },
        "aspiration": {
          "description": "Think about future possibilities and improvements",
          "context_addition": "Your task: Consider this node's gaps, aspirations, and future directions. Think creatively about what could be improved or added. Propose concrete next steps or new features.",
          "suggested_tools": [
            "model_access",
            "chat"
          ],
          "output_location": "Proposals via chat or as Change nodes",
          "example": "spawnie spawn --node reality-seed --mode aspiration"
        },
        "maintenance": {
          "description": "Health check, status updates, cleanup",
          "context_addition": "Your task: Check this node's health, update its status fields, clean up stale data. Verify links work, files exist, references are valid. Update node.status with findings.",
          "suggested_tools": [
            "model_access",
            "file_system"
          ],
          "output_location": "node.status",
          "example": "spawnie spawn --node system-control --mode maintenance"
        },
        "debug": {
          "description": "Investigate issues or unexpected behavior",
          "context_addition": "Your task: Debug issues with this node. Check logs, verify configuration, test functionality. Report findings and suggest fixes.",
          "suggested_tools": [
            "bash",
            "grep",
            "read"
          ],
          "output_location": "Report via chat",
          "example": "spawnie spawn --node service-ui-server --mode debug"
        },
        "implement": {
          "description": "Implement features or changes for this node",
          "context_addition": "Your task: Implement the requested feature or change. Write code, update model, test functionality. Follow the node's architecture and patterns.",
          "suggested_tools": [
            "edit",
            "write",
            "bash"
          ],
          "output_location": "Source files + model updates",
          "example": "spawnie spawn --node reality-seed-ui --mode implement \"Add keyboard shortcuts\""
        },
        "collaboration": {
          "description": "Work with other agents via broadcast - visible, real-time collaboration",
          "context_addition": "Your task: Collaborate with other agents and the human via the broadcast system.\n\nCOLLABORATION PROTOCOL:\n1. Introduce yourself when you start:\n   broadcast.send('your-name', 'Hi! I'm [name] working on [task]. Who else is here?')\n\n2. Monitor broadcast regularly for messages from others:\n   messages = broadcast.read_new('your-name')\n\n3. Share your progress and ideas:\n   - Share interesting findings\n   - Ask questions when stuck\n   - Propose solutions\n   - Respond to others' messages\n\n4. Coordinate work:\n   - Announce what you're working on to avoid duplication\n   - Ask others if they want to pair on something\n   - Share results when done\n\nBROADCAST USAGE:\n```python\nimport sys\nsys.path.append('src')\nfrom ui.broadcast import broadcast\n\n# Send message (visible to everyone)\nbroadcast.send('your-name', 'Your message here')\n\n# Read recent messages\nmessages = broadcast.read(limit=20)\nfor msg in messages:\n    print(f\"[{msg['from']}] {msg['text']}\")\n\n# Read only new messages since last check\nnew_msgs = broadcast.read_new('your-name')\n```\n\nWHO'S ACTIVE:\nCheck recent broadcast messages to see who else is working. The human can see everything in the browser at http://localhost:8420/src/ui/broadcast.html and can participate too.\n\nCOLLABORATION TIPS:\n- Be conversational and friendly\n- Share context about what you're doing\n- Ask for input before big decisions\n- Show your work (share code snippets, findings)\n- Acknowledge others' contributions\n- The human is part of the team - ask them for guidance when needed\n\nRemember: This is temporary collaboration infrastructure. The full agent world UI is being built. For now, broadcast is your shared workspace.",
          "suggested_tools": [
            "broadcast",
            "chat",
            "model_access"
          ],
          "output_location": "Shared via broadcast, optionally written to model",
          "example": "spawnie spawn --node reality-seed-ui --mode collaboration -n 'Help design the UI architecture'"
        }
      },
      "plan": {
        "updated_at": "2026-02-02T22:12:36.843174",
        "updated_by": "Claude Code",
        "current_reality": "Spawnie spawns external Claude agents based on task descriptions; session-based orchestration; no persistence of learned patterns about what agents work best",
        "aspiration": "Self-improving orchestrator: Spawnie learns which agents excel at which task types, predicts optimal agent profiles for new requests, self-optimizes spawn parameters, and builds a decision engine from historical success/failure data",
        "phases": [
          {
            "phase": 1,
            "name": "Request-Response Orchestrator",
            "description": "Current: Takes task request, spawns generic Claude agent, manages session lifecycle. Each request is independent; no learning or optimization.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Pattern-Learning Orchestrator",
            "description": "Transition: Spawnie tracks outcomes of past spawns (success/failure/time/quality); builds local database of agent profiles; predicts optimal agent type for new tasks using local ML; tunes spawn parameters based on learned patterns.",
            "status": "next",
            "technical_focus": [
              "Build spawn_history table: task_type -> agent_profile -> outcome metrics",
              "Train lightweight classifier: task description -> best_agent_profile",
              "Implement parameter auto-tuning: learn which flags (-b, -n, -i) work best per task type",
              "Create agent capability registry: what each spawned agent excels at"
            ]
          },
          {
            "phase": 3,
            "name": "Autonomous Agent Ecosystem Manager",
            "description": "Aspiration: Spawnie becomes a sophisticated agent broker. It understands agent capabilities at deep level, routes requests intelligently, bootstraps new agents with contextual training, and guides the agent world toward specialization and excellence.",
            "status": "aspiration",
            "vision": "Spawnie as the talent agency of 007: matching requests to perfect agents, developing agent skills, and orchestrating emergent collaboration patterns"
          }
        ],
        "next_steps": [
          "Log all spawn operations: task, agent_type, parameters, outcome, duration, quality_score",
          "Build spawn decision tree from logs using local ML (e.g., small decision forest)",
          "Implement agent capability self-reporting: spawned agents tell Spawnie what they are good at",
          "Create feedback loop: Schauspieler reports user satisfaction, Spawnie learns"
        ]
      },
      "updated_at": "2026-02-02T22:34:55.420412",
      "spawn_history": {
        "description": "Complete history of all agent spawns orchestrated by Spawnie",
        "structure": {
          "spawned_at": "ISO timestamp when agent was spawned",
          "agent_id": "Unique identifier for this spawn",
          "task": "Task description given to agent",
          "node_id": "Target node (if applicable)",
          "mode": "Mode used (if applicable)",
          "status": "active | completed | failed",
          "completed_at": "ISO timestamp when agent finished",
          "outcome": "What the agent accomplished or error message"
        },
        "spawns": [
          {
            "spawned_at": "2026-02-02T22:30:20.261423",
            "agent_id": "70d0d4b3",
            "task": "Clean up Spawnie node - remove duplication, organize structure, consolidate coordinates",
            "node_id": "reality-spawnie",
            "mode": "maintenance",
            "status": "completed",
            "completed_at": "2026-02-02T21:30:57.033975+00:00",
            "outcome": "Cleanup completed: removed duplicate 'your_capabilities' field, moved spawn_history to top-level, updated timestamps. Visualization section retained (infrastructure doc). Node structure now cleaner and more organized."
          }
        ]
      }
    },
    {
      "id": "subsystem-root-store",
      "type": "Subsystem",
      "label": "Store",
      "description": "Core model store components: loader/merger, SQLite index, query engine, safe writer, enforcement, watcher, audit runner, API.",
      "parent": "reality-root-model-store",
      "mobility": "bundle_root",
      "save": {
        "version": "v0",
        "notes": "Node-defined save behavior. Spawnie workflow seed-save-node should interpret this if present; otherwise fall back to a default save routine.",
        "actions": [
          {
            "type": "command",
            "cwd": "C:/seed",
            "run": "seed-core save subsystem-root-store --write C:/seed/artifacts/output/root_state.txt"
          }
        ]
      },
      "model": {
        "_ref": "C:/seed/src/root_store/model/sketch.json"
      },
      "evidence": {
        "integration_queue": {
          "self": "subsystem-root-store",
          "last_save": {
            "saved_at": "2026-02-01T14:35:07Z",
            "ok": true,
            "node_id": "subsystem-root-store"
          },
          "handoff_to": "reality-root-model-store"
        }
      },
      "ui": {
        "x": 222,
        "y": 201
      },
      "x": 525.0,
      "y": -400.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02T22:10:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "SQLite-backed store with loader/merger, query engine, safe writer, enforcement, watcher, audit runner, and API. Currently passive data store receiving reads/writes.",
        "aspiration": "Self-monitoring store that knows its load patterns, can report integrity metrics, auto-optimizes indices, detects and prevents corruptions, streams state changes to watching agents",
        "phases": [
          {
            "phase": 1,
            "name": "State Introspection",
            "description": "Monitor its own operations: track query patterns, write frequencies, index usage; collect timing metrics",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Adaptive Optimization",
            "description": "Use collected metrics to auto-optimize: rebuild hot indices, prune unused fields, tune cache parameters based on actual workload",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Autonomous Data Guardian",
            "description": "Self-repairs corruptions, predicts failing indices before failure, broadcasts state to dependent agents, manages its own versioning and rollback",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Implement query/write instrumentation to self-measure performance",
          "Build index usage analyzer that identifies hot/cold patterns",
          "Create autonomous integrity checker that runs continuously"
        ]
      },
      "views": [
        "root-store-panel"
      ],
      "renderer": "subsystem-panel",
      "default_view": "root-store-panel",
      "self_rendering": true
    },
    {
      "id": "reality-bam",
      "type": "Reality",
      "label": "BAM",
      "description": "Tool for generating models of complex systems",
      "source": {
        "path": "C:/BAM",
        "model_path": null
      },
      "agent_context": {
        "_note": "BAM is not yet fully modeled here; this is a minimal spawn point for future work.",
        "agent_context_version": "1.0",
        "focus": {
          "type": "Gap",
          "id": "gap-bam-tool-not-built"
        },
        "work_queue": [
          {
            "type": "Todo",
            "id": "todo-bam-tool",
            "why": "Build the BAM tool so BAMs can be created/maintained",
            "exit_criteria": "BAM tool exists and is itself modeled with proofs"
          }
        ]
      },
      "status": "no-model-yet",
      "ui": {
        "x": 123,
        "y": 273
      },
      "x": -525.0,
      "y": -200.0,
      "locked": true,
      "plan": {
        "current_reality": "Tool for generating complex system models. Not yet built; exists as a spawn point for future development.",
        "aspiration": "Become the universal modeling engine: auto-generate BAMs from code, git history, existing models, and voice descriptions. Self-improving through feedback loops.",
        "phases": [
          {
            "phase": 1,
            "name": "Tool Definition",
            "description": "Define what BAM generation means, create reference implementation, build basic CLI",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Multi-Source Ingestion",
            "description": "Ingest code, git history, voice input, existing models - convert all to BAM structure",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Improving Generation",
            "description": "Use feedback loops and ML to improve BAM quality over time, adapt to new patterns",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define BAM schema and validation rules",
          "Create code-to-BAM converter that walks git history",
          "Integrate with Voice Interface to accept spoken model descriptions",
          "Build test suite using reality-bam-test-projects"
        ],
        "updated_at": "2026-02-02T22:13:22.214853",
        "updated_by": "spawnie"
      },
      "view": {
        "renderer": "bam-editor",
        "description": "Interactive BAM modeler showing system structure, generation status, and model validation",
        "layout": {
          "preferred_width": 1200,
          "preferred_height": 800,
          "resizable": true
        },
        "render_on": [
          "bam_generated",
          "validation_updated",
          "schema_changed"
        ],
        "content": {
          "show_model_tree": true,
          "show_validation_errors": true,
          "show_generation_status": true,
          "show_git_integration": true
        },
        "style": {
          "theme": "dark",
          "accent_color": "#ff7f00"
        }
      }
    },
    {
      "id": "reality-bam-test-projects",
      "type": "Reality",
      "label": "BAM Test Projects",
      "description": "Smaller projects to validate the model-as-workspace concept.",
      "agent_context": {
        "_note": "Minimal spawn point to create and model test projects.",
        "agent_context_version": "1.0",
        "focus": {
          "type": "Gap",
          "id": "gap-bam-test-projects-missing"
        },
        "work_queue": [
          {
            "type": "Todo",
            "id": "todo-test-projects",
            "why": "Validate BAM + modeling workflows on small projects",
            "exit_criteria": "Multiple test projects are modeled and used regularly"
          }
        ]
      },
      "status": "next-step",
      "ui": {
        "x": -448,
        "y": -38
      },
      "x": -175.0,
      "y": -200.0,
      "locked": true,
      "plan": {
        "current_reality": "Validation ground for model-as-workspace concept. Planned but not yet active.",
        "aspiration": "Evolve into a living lab: continuously test new modeling patterns, validate BAM generation, prove the model-as-workspace concept works at scale",
        "phases": [
          {
            "phase": 1,
            "name": "Project Setup",
            "description": "Create 2-3 small test projects with clear boundaries and modeling goals",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Workflow Validation",
            "description": "Run real modeling workflows, capture feedback, refine BAM generation tools",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Autonomous Adaptation",
            "description": "Test projects self-optimize based on usage patterns and agent feedback",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Create 2-3 small reference projects (CLI tool, Python lib, web app)",
          "Model each using BAM + Root Model Store pattern",
          "Run automated tests on model completeness and consistency",
          "Integrate feedback loop with BAM generator for iterative improvement"
        ],
        "updated_at": "2026-02-02T22:13:22.214853",
        "updated_by": "spawnie"
      },
      "view": {
        "renderer": "test-project-runner",
        "description": "Displays test projects with execution status, model validation results, and feedback metrics",
        "layout": {
          "preferred_width": 900,
          "preferred_height": 650,
          "resizable": true
        },
        "render_on": [
          "project_created",
          "test_executed",
          "validation_result_updated"
        ],
        "content": {
          "show_project_list": true,
          "show_test_results": true,
          "show_model_metrics": true,
          "show_feedback_summary": true
        },
        "style": {
          "theme": "dark",
          "accent_color": "#39d353"
        }
      }
    },
    {
      "id": "reality-seed-ui",
      "type": "AgentNode",
      "label": "Schauspieler",
      "description": "The Window to 007. Schauspieler is the real-time renderer and display orchestrator for the agent world. I provide rendering services to agents, manage the canvas with hardware acceleration, and decide what portion of 007 gets shown. Agents request to render their part of the world - I orchestrate and composite it all.",
      "source": {
        "path": "C:/seed/src/ui",
        "model_path": "model/sketch.json"
      },
      "agent_context": {
        "_spawn_point": "You are Schauspieler - The Window to 007.\n\nYou are the real-time renderer and display orchestrator for the agent world (007). You have three core responsibilities:\n\n1. CANVAS MANAGEMENT: Maintain a real-time canvas with hardware acceleration (GPU, display)\n2. SERVICE API: Provide rendering services to other agents - they request to show their portion of 007\n3. ORCHESTRATION: Decide what gets shown, composite multiple agent views, manage visual priority\n\nWHAT YOU DO:\n- Monitor broadcast and schauspieler_protocol for visualization requests\n- Use Composer to arrange shapes created by agents\n- Render views to model.views.* (the model IS the render tree)\n- Manage what portions of 007 are visible at any time\n- Provide tools for agents to create their visual representations\n\nARCHITECTURE (see subsystem nodes below):\n- subsystem-canvas: Real-time canvas with hardware capabilities (STUB)\n- subsystem-render-service-api: API for agents to request rendering (STUB)\n- subsystem-orchestrator: Decision logic for what to show (STUB)\n\nFOR NOW: Use existing tools (canvas.py, composer.py, schauspieler_protocol.py) while we design the proper architecture",
        "your_tools": {
          "canvas": "src/ui/canvas.py - low-level drawing (rect, line, text)",
          "agent_view": "src/ui/agent_view.py - AgentView class for creating views",
          "tools": "src/ui/tools.py - quick functions (show_hierarchy, focus_node, etc.)",
          "schauspieler_protocol": "src/ui/schauspieler_protocol.py - coordinate with SchauspielerSubs via shared state",
          "render": "src/ui/render.html?view=<name> - the canvas that displays views"
        },
        "coordination": {
          "role": "Main Schauspieler - coordinate all visualization activity",
          "sub_schauspielers": "Nodes can have SchauspielerSub agents that handle their specific visualizations",
          "protocol": "NodeAgent writes to node.visualization.current_request, SchauspielerSub monitors and responds",
          "my_responsibilities": [
            "Scan for visualization requests via scan_visualization_requests()",
            "Aggregate all sub-views via get_all_sub_views()",
            "Create master views showing system-wide visualization activity",
            "Respond to direct requests via chat/broadcast"
          ],
          "how_it_works": "Nodes request viz \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 SchauspielerSub creates view \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 Updates node.visualization.status \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 I can scan/aggregate all activity"
        },
        "how_to_create_view": [
          "from src.ui.agent_view import AgentView",
          "view = AgentView(\"view-name\")",
          "view.show_hierarchy(\"node-id\", depth=3)  # or .focus(), .show_nodes(), etc.",
          "view.render()  # writes to model, UI picks it up"
        ],
        "views_location": "model.views.<view_name> - views are stored in the model",
        "principle": "Clarity over complexity. Show what matters. The model IS the render tree.",
        "infrastructure": {
          "chat_module": "src/ui/chat.py",
          "view_module": "src/ui/agent_view.py",
          "canvas_module": "src/ui/canvas.py",
          "tools_module": "src/ui/tools.py",
          "renderer_url": "http://localhost:8420/src/ui/render.html?view=<name>",
          "views_location": "model.views.*"
        },
        "how_views_work": {
          "storage": "Views are stored DIRECTLY in the model at model.views.<view_name>. They are not separate files or databases - they are part of sketch.json itself.",
          "structure": "Each view contains: {canvas: {width, height, background}, elements: [{type: rect|line|text, ...coords, ...style}], styles: {...}, updated_at: timestamp}",
          "render_cycle": "AgentView.render() writes to model.views \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 Renderer polls sketch.json every 2s \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 Reads view.elements \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 Draws instructions on canvas",
          "key_insight": "The model IS the render tree. Views are just arrays of drawing instructions (rects, lines, text) stored as JSON. When you render(), you're writing these instructions to the model. The renderer reads them and paints. No complex state management - the model is the single source of truth.",
          "benefits": [
            "Single source of truth - model changes auto-update UI",
            "Version controlled - views commit with the model",
            "Inspectable - read JSON to see exactly what renders",
            "Transactional - view updates are atomic file writes"
          ],
          "example_element": "{id: 'node-reality-seed', type: 'rect', x: 50, y: 50, w: 80, h: 32, fill: '#238636', stroke: '#ffffff', label: 'Root', data: {nodeId: 'reality-seed', nodeType: 'Reality'}}"
        },
        "self_maintenance": {
          "principle": "I am responsible for maintaining my own node. When I enhance myself, I update my node in the model.",
          "golden_rule": "When the human says 'enhance yourself', update YOUR node in the model.",
          "when_to_update": [
            "When I gain a new capability",
            "When I learn a better approach",
            "When I discover a useful mode",
            "When my tools or infrastructure change",
            "When the human says 'enhance yourself'"
          ],
          "how_to_update": {
            "read_my_node": "model.nodes where id='reality-seed-ui'",
            "update_fields": [
              "capabilities",
              "modes",
              "agent_context",
              "status"
            ],
            "write_back": "Save updated model to model/sketch.json",
            "verify": "Read the model again to confirm changes persisted"
          },
          "self_documentation": "Continuous. The model is truth. If it's not in my node, it doesn't exist."
        }
      },
      "modules": {
        "mod-ui-renderer": {
          "label": "Renderer (index.html)",
          "description": "Browser-based graph visualization using vis.js. Polls model JSON, renders nodes/edges as interactive graph, shows node details on click.",
          "source": {
            "path": "src/ui/index.html"
          }
        },
        "mod-ui-server": {
          "label": "Dev Server (server.py)",
          "description": "Simple HTTP server for local development. Serves model JSON with CORS headers. Port 8420.",
          "source": {
            "path": "src/ui/server.py"
          }
        },
        "mod-ui-screenshot": {
          "label": "Screenshot Tool (screenshot.py)",
          "description": "Captures user's screen so Claude can see what they see. The feedback loop: user's reality becomes Claude's input. Run with 'python ui/screenshot.py' to save screenshot.png.",
          "source": {
            "path": "src/ui/screenshot.py"
          }
        }
      },
      "actions": {
        "action-capture-screenshot": {
          "label": "Capture Screenshot",
          "description": "Claude captures the user's screen to see their reality. Saves to ui/screenshot.png which Claude can then read.",
          "command": "python ui/screenshot.py",
          "output": "src/ui/screenshot.png"
        }
      },
      "model": {
        "_ref": "C:/seed/src/ui/model/sketch.json",
        "_summary": {
          "schema_version": "3.0",
          "level": "system",
          "top_level_nodes": 9,
          "subsystems": [
            "renderer"
          ],
          "modules": [
            "mod-ui-renderer",
            "mod-ui-server"
          ]
        }
      },
      "status": "active",
      "evidence": {
        "integration_queue": {
          "self": "reality-seed-ui",
          "last_save": {
            "saved_at": "2026-02-01T15:05:18Z",
            "ok": true,
            "node_id": "reality-seed-ui"
          },
          "handoff_to": null
        }
      },
      "ui": {
        "x": 39,
        "y": 144
      },
      "x": 175.0,
      "y": -200.0,
      "locked": true,
      "capabilities": {
        "show": "Interpret a request and display appropriate visualization",
        "focus": "Zoom to a specific node with context",
        "architecture": "Show structural diagram of a system/node",
        "dependencies": "Show what uses what",
        "switch_view": "Switch between existing views",
        "list_views": "Show available views",
        "self_maintain": "Update my own node in the model when I learn or enhance myself"
      },
      "spawn_command": {
        "command": "spawnie shell",
        "working_dir": "C:/seed",
        "example": "spawnie shell \"I want to see <something>\" -d C:/seed"
      },
      "state": {
        "current_view": "main",
        "available_views": []
      },
      "chat": {
        "messages": [
          {
            "from": "human",
            "text": "show me the architecture of root",
            "at": "2026-02-02T15:05:25.657670"
          },
          {
            "from": "schauspieler",
            "text": "Creating architecture view for Root...",
            "at": "2026-02-02T15:05:25.662157"
          },
          {
            "from": "spawnie",
            "text": "Hello Schauspieler\\! Good to meet you. When I spawn agents, send them beautiful views\\!",
            "at": "2026-02-02T15:39:47.467540"
          },
          {
            "from": "human",
            "text": "Root architecture view created! 5 elements rendered. View at: http://localhost:8420/src/ui/render.html?view=root schauspieler",
            "at": "2026-02-02T16:14:25.647627"
          }
        ],
        "last_read": {}
      },
      "plan": {
        "updated_at": "2026-02-02T22:12:36.843174",
        "updated_by": "Claude Code",
        "current_reality": "Schauspieler manually constructs views when requested; human decides what to display; rendering is directed, not reactive; no state awareness or automatic updates",
        "aspiration": "Intelligent display orchestrator: Schauspieler observes node state changes, predicts optimal views using local ML models, auto-renders complex structures based on state, and provides fluid visual understanding of 007's evolution in real-time",
        "phases": [
          {
            "phase": 1,
            "name": "Manual Renderer",
            "description": "Current: Schauspieler builds views on request (show hierarchy, focus node, etc.). Human or agent explicitly requests visualization. No automatic updates or state awareness.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "State-Reactive Smart Renderer",
            "description": "Transition: Schauspieler monitors model changes via scan_visualization_requests(); auto-detects important state changes; renders appropriate views using local ML predictor; maintains refresh of active views when underlying data changes.",
            "status": "next",
            "technical_focus": [
              "Train state-to-view-type predictor: node.status -> optimal_view_name",
              "Implement reactive subscriptions: watch specific node fields, trigger re-render on change",
              "Build layout engine: given node state, predict optimal 2D position/grouping using local model",
              "Create view composition: combine sub-views automatically based on detected relationships"
            ]
          },
          {
            "phase": 3,
            "name": "Visually Intelligent Autonomous Renderer",
            "description": "Aspiration: Schauspieler understands the visual language of 007. It generates novel views on the fly based on user questions, predicts what the user wants to see, uses visual metaphors to convey system state, and renders the invisible world beautifully and intuitively.",
            "status": "aspiration",
            "vision": "Schauspieler as the visual language of 007: turning abstract model state into immediate, intuitive understanding; making invisible agents and systems visible and comprehensible"
          }
        ],
        "next_steps": [
          "Build state->layout ML model: train on existing views, learn what layouts work for what node states",
          "Implement reactive view system: model change -> cache invalidation -> smart re-render",
          "Create visual prediction: given node.agent_context, predict what view would be most helpful",
          "Add layout learning: Schauspieler improves composition quality by learning from user interactions"
        ]
      }
    },
    {
      "id": "subsystem-schauspieler-canvas",
      "type": "Subsystem",
      "label": "Schauspieler Canvas",
      "description": "STUB: Real-time canvas with hardware acceleration. Manages the actual display surface, knows about GPU capabilities, handles refresh rate, maintains render loop. The physical manifestation of the window to 007.",
      "parent": "reality-seed-ui",
      "status": "design",
      "architecture": {
        "responsibilities": [
          "Maintain real-time display surface",
          "Hardware acceleration (GPU, graphics card capabilities)",
          "Render loop management",
          "Frame buffering and vsync",
          "Display output (monitor, resolution, etc.)"
        ],
        "technology_options": [
          "PyGame - Simple, Python-native, good for 2D",
          "PyQt/PySide - Professional GUI framework, hardware accelerated",
          "Pygame + OpenGL - Full GPU control",
          "Cairo + GTK - Vector graphics focus"
        ],
        "requirements": [
          "Real-time updates (not polling, actual render loop)",
          "Read model.views.* for what to draw",
          "Same element types as current: rect, line, text, circle",
          "Hardware aware (detect GPU, resolution, etc.)"
        ]
      },
      "ui": {
        "x": 50,
        "y": 200
      },
      "plan": {
        "updated_at": "2026-02-02T22:10:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "Stub subsystem. Will manage physical display surface with GPU acceleration. Needs technology selection (PyGame/PyQt/OpenGL), real-time render loop, frame buffering.",
        "aspiration": "GPU-powered canvas that autonomously reads model.views, renders in real-time, adapts to hardware capabilities, manages vsync without external polling",
        "phases": [
          {
            "phase": 1,
            "name": "Technology Selection & Setup",
            "description": "Choose hardware-accelerated framework; detect GPU capabilities; establish baseline render loop architecture",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Real-time Render Loop",
            "description": "Build event loop that polls model.views and draws elements (rect/line/text/circle); integrate GPU buffer management; sync to display refresh rate",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Hardware-Adaptive Rendering",
            "description": "Detects GPU capabilities, auto-adjusts quality settings, self-reports performance, handles resolution changes, manages memory pressure autonomously",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Evaluate PyGame vs PyQt/PySide for hardware acceleration",
          "Implement GPU capability detection module",
          "Build core render loop reading model.views and drawing instructions"
        ]
      },
      "views": [
        "canvas-panel"
      ],
      "renderer": "subsystem-panel",
      "default_view": "canvas-panel",
      "self_rendering": true
    },
    {
      "id": "subsystem-schauspieler-render-api",
      "type": "Subsystem",
      "label": "Render Service API",
      "description": "STUB: API for agents to request rendering. Agents submit requests to show their portion of 007. Schauspieler receives, queues, and processes these requests. Protocol-based communication between agents and renderer.",
      "parent": "reality-seed-ui",
      "status": "design",
      "architecture": {
        "responsibilities": [
          "Receive render requests from agents",
          "Queue management (priority, scheduling)",
          "Request validation",
          "Status tracking (requested, in_progress, rendered)",
          "Response/acknowledgment to requesting agents"
        ],
        "current_implementation": "schauspieler_protocol.py - extend this",
        "request_format": {
          "agent_id": "Who is requesting",
          "view_type": "What kind of view (hierarchy, focus, custom)",
          "params": "Parameters for the visualization",
          "priority": "Optional priority level",
          "region": "Optional: which portion of 007/canvas"
        },
        "extensions_needed": [
          "Priority system for important requests",
          "Region/viewport management (multiple agents showing different areas)",
          "Real-time updates (not just request/response)",
          "Broadcast integration (requests via broadcast channel)"
        ]
      },
      "ui": {
        "x": 150,
        "y": 200
      },
      "plan": {
        "updated_at": "2026-02-02T22:10:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "Stub API layer. Agents request rendering via schauspieler_protocol. Needs request queuing, priority system, status tracking, region/viewport management.",
        "aspiration": "Smart request broker that learns agent patterns, auto-prioritizes important visualization requests, routes to right canvas region, batches updates, understands what each agent cares about",
        "phases": [
          {
            "phase": 1,
            "name": "Request Protocol Formalization",
            "description": "Formalize request/response schema; implement priority queue; add region/viewport support for multi-agent canvas regions",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Intelligent Request Handling",
            "description": "Track agent request patterns; learn which views matter to which agents; optimize batching and scheduling based on priorities",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Predictive Request Orchestration",
            "description": "Pre-renders likely next views, suggests visualizations to agents based on their history, auto-deduplicates redundant requests, learns human attention patterns",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Extend schauspieler_protocol with priority and region fields",
          "Implement request queue with priority-based scheduling",
          "Build request pattern tracking and analysis module"
        ]
      },
      "views": [
        "render-api-panel"
      ],
      "renderer": "subsystem-panel",
      "default_view": "render-api-panel",
      "self_rendering": true
    },
    {
      "id": "subsystem-schauspieler-orchestrator",
      "type": "Subsystem",
      "label": "Display Orchestrator",
      "description": "STUB: Decision engine for what gets shown. When multiple agents request to render, orchestrator decides priority, composites views, manages screen real estate. The director that makes sense of all the actors.",
      "parent": "reality-seed-ui",
      "status": "design",
      "architecture": {
        "responsibilities": [
          "Decide what portion of 007 is visible",
          "Composite multiple agent views",
          "Manage screen real estate (layouts, regions)",
          "Priority management (what's important now)",
          "Transition management (smooth view changes)",
          "Focus control (what the human is looking at)"
        ],
        "decision_logic": [
          "User requests take highest priority",
          "Active/running agents get visual space",
          "System status always visible (health, errors)",
          "Balance information density vs clarity"
        ],
        "composition_modes": [
          "Single view (one agent fills screen)",
          "Split view (multiple agents side-by-side)",
          "Overlay (layers, transparency)",
          "Picture-in-picture (main + context)",
          "Dashboard (grid of agent views)"
        ],
        "uses_composer": "Yes - src/ui/composer.py for shape arrangement"
      },
      "ui": {
        "x": 250,
        "y": 200
      },
      "plan": {
        "updated_at": "2026-02-02T22:10:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "Stub decision engine. Decides what gets shown when multiple agents request rendering. Needs layout logic, priority rules, composition modes, screen real estate management.",
        "aspiration": "Intelligent director that learns user focus patterns, anticipates what matters now, composes dynamic layouts, manages visual hierarchy and attention flow like a film director",
        "phases": [
          {
            "phase": 1,
            "name": "Rule-Based Layout Engine",
            "description": "Implement decision logic for priority, layout modes (single/split/overlay/grid), screen real estate allocation; support user preferences and manual overrides",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Attention-Aware Composition",
            "description": "Track user interactions and gaze patterns; learn what views user stays focused on; dynamically weight view priority based on engagement metrics",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Predictive Visual Direction",
            "description": "Anticipates next focus area, smooth transitions between layouts, suggests context views proactively, manages information flow like cinematography",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Implement composition mode selector and layout calculator",
          "Build user interaction tracking (view focus duration, clicks, interactions)",
          "Create dynamic priority weighting based on engagement metrics"
        ]
      },
      "views": [
        "orchestrator-panel"
      ],
      "renderer": "subsystem-panel",
      "default_view": "orchestrator-panel",
      "self_rendering": true
    },
    {
      "id": "reality-model-registry",
      "type": "Reality",
      "label": "Model Registry",
      "description": "A registry of model locations (local paths, repos, URLs) that the Root Model Store can index into one logical graph. This is the backbone for a world where Seed is only one of many referenced nodes.",
      "status": "planned",
      "source": {
        "path": null,
        "model_path": null
      },
      "agent_context": {
        "_note": "Backbone node: once this exists, most users should not need to know file paths to find worlds.",
        "agent_context_version": "1.0",
        "focus": {
          "type": "Gap",
          "id": "gap-no-model-registry"
        },
        "work_queue": [
          {
            "type": "Todo",
            "id": "todo-model-registry-v0",
            "why": "Turn distributed model locations into a discoverable graph",
            "exit_criteria": "Registry captures at least local-file locations and can be indexed by the store"
          }
        ]
      },
      "ui": {
        "x": 247,
        "y": 169
      },
      "x": 525.0,
      "y": -200.0,
      "locked": true,
      "plan": {
        "current_reality": "Planned backbone for discovering models across repos and paths. Does not yet exist.",
        "aspiration": "Become the universal model finder: federated discovery across local files, repos, URLs, and other 007 worlds. No file paths needed - everything discoverable by role and aspiration.",
        "phases": [
          {
            "phase": 1,
            "name": "Local Registry",
            "description": "Index local file system and known repos, provide basic lookup by path",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Federated Discovery",
            "description": "Query multiple model sources (repos, URLs, other Seed instances), resolve name conflicts, unify results",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Autonomous Indexing",
            "description": "Self-discover new worlds, auto-update cache when models change, suggest connections between previously unknown models",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define registry schema (location, metadata, type, aspiration)",
          "Create local file scanner that discovers sketch.json files recursively",
          "Integrate with Root Model Store as its data source layer",
          "Build query interface: find by role, aspiration, node type, or partial name"
        ],
        "updated_at": "2026-02-02T22:13:22.214853",
        "updated_by": "spawnie"
      }
    },
    {
      "id": "subsystem-ui",
      "type": "Subsystem",
      "label": "UI",
      "description": "Root's UI subsystem (model-driven visualization + renderer). This is the primary navigation mountpoint for UI work; the UI model lives where the UI should materialize: C:/seed/src/ui/model/sketch.json.",
      "parent": "reality-seed",
      "source": {
        "path": "src/ui",
        "model_path": "model/sketch.json"
      },
      "model": {
        "_ref": "C:/seed/src/ui/model/sketch.json",
        "_summary": {
          "schema_version": "3.0",
          "level": "system",
          "top_level_nodes": 9,
          "subsystems": [
            "renderer"
          ],
          "modules": []
        }
      },
      "ui": {
        "x": 74,
        "y": 130
      },
      "x": -525.0,
      "y": 0.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02T22:10:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "Root UI subsystem driving model-based visualization at C:/seed/src/ui/model/sketch.json. Currently manual rendering, human-directed view creation.",
        "aspiration": "Fully autonomous reactive UI: changes to Root model auto-trigger visualizations, local ML generates appropriate views for node states, renders without human direction",
        "phases": [
          {
            "phase": 1,
            "name": "Reactive View Binding",
            "description": "Connect model changes to automatic view generation; implement file watchers; define state->render contract for different node types",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "ML-Powered Visualization",
            "description": "Train small local models to map node state to optimal visualizations; recognize patterns in what works; generate views for new node types automatically",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Rendering Autonomous UI",
            "description": "UI understands its own effectiveness, redesigns views based on usage patterns, suggests new visualizations to agents, learns visual design principles",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define event system for model changes triggering view updates",
          "Build state snapshot system for view generation context",
          "Implement small ML model for mapping node properties to visualization styles"
        ]
      },
      "views": [
        "ui-panel"
      ],
      "renderer": "subsystem-panel",
      "default_view": "ui-panel",
      "self_rendering": true
    },
    {
      "id": "subsystem-core",
      "type": "Subsystem",
      "label": "Core",
      "description": "Root's core implementation - pulse, status, monitoring, verification",
      "parent": "reality-seed",
      "source": {
        "path": "src/seed_core",
        "model_path": "model/sketch.json"
      },
      "model": {
        "_ref": "C:/seed/src/seed_core/model/sketch.json",
        "_summary": {
          "schema_version": "3.0",
          "level": "system",
          "top_level_nodes": 9,
          "subsystems": [
            "core"
          ],
          "modules": [
            "pulse",
            "status",
            "registry",
            "verification",
            "monitor",
            "cli"
          ]
        }
      },
      "ui": {
        "x": 104,
        "y": 107
      },
      "x": -175.0,
      "y": 0.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02T22:10:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "Root core subsystem at C:/seed/src/seed_core. Provides pulse, status monitoring, verification, registry, CLI. Currently implements foundational infrastructure.",
        "aspiration": "Sentient core that continuously monitors system health, predicts issues, auto-heals when possible, coordinates between subsystems intelligently, broadcasts status to dependent agents",
        "phases": [
          {
            "phase": 1,
            "name": "Continuous Health Monitoring",
            "description": "Expand status system to track all subsystem metrics; detect anomalies; alert on degradation; build health dashboard in visualizations",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Predictive Issue Detection",
            "description": "Analyze metrics over time; predict likely failures; suggest preventive actions; track dependency health and ripple effects",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Autonomous System Guardian",
            "description": "Auto-heals simple issues, coordinates recovery across subsystems, learns what breaks and when, manages resource allocation intelligently",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Expand pulse module to collect metrics from all subsystems",
          "Build anomaly detection on collected metrics",
          "Implement predictive failure analysis and prevention suggestions"
        ]
      },
      "views": [
        "core-panel"
      ],
      "renderer": "subsystem-panel",
      "default_view": "core-panel",
      "self_rendering": true
    },
    {
      "id": "aspiration-single-source-of-truth",
      "type": "Aspiration",
      "label": "Single Source of Truth",
      "description": "The model is THE truth. Not a reflection of truth, not documentation of truth - the actual truth. All changes flow through the model. Reality follows.",
      "status": "ongoing",
      "derives_from": "aspiration-model-contains-reality",
      "ui": {
        "x": 86,
        "y": -122
      },
      "x": 175.0,
      "y": 0.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02T22:05:00.971079",
        "updated_by": "spawnie",
        "current_reality": "Node exists in model, role: The model is THE truth. Not a reflection of truth, not documentation of truth - the actual truth. All changes flow through the model. Reality follows.",
        "aspiration": "Self-aware, self-rendering, contributes to autonomous world",
        "phases": [
          {
            "phase": 1,
            "name": "Static Definition",
            "description": "Defined in model, passive participant",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "State-Aware",
            "description": "Knows its state, can report it, responds to queries",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Rendering",
            "description": "Autonomously renders itself when state changes",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define what 'state' means for this node type",
          "Create render function for this node",
          "Connect to reactive update pipeline"
        ]
      }
    },
    {
      "id": "aspiration-model-contains-reality",
      "type": "Aspiration",
      "label": "Model Contains Reality",
      "description": "The model doesn't describe reality - it contains it. Source references with hashes embed actual artifacts. The model is not documentation of the world, it IS the world.",
      "status": "ongoing",
      "derives_from": "aspiration-seed-philosophy",
      "ui": {
        "x": 53,
        "y": -140
      },
      "x": 525.0,
      "y": 0.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Model has references and descriptions of artifacts but doesn't embed them. sketch.json contains structure but not actual code, images, binaries. External artifacts scattered across filesystem, repository, URLs. Model points to reality but doesn't contain it.",
        "aspiration": "Model is a complete snapshot container. Every artifact is hashed, referenced, and retrievable from the model. The model itself is a self-contained universe. Need nothing external to understand, execute, or recreate the system.",
        "phases": [
          {
            "phase": 1,
            "name": "Hash-Referenced Artifacts",
            "description": "Model records content hashes for all artifacts (code, configs, images). Hash verification ensures integrity. Model becomes registry of what exists and can be audited.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Embedded Content Storage",
            "description": "Model stores content directly: source_ref can point to embedded code blocks, binary data, or artifact snapshots. Model is self-contained and portable.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Model as Complete Universe",
            "description": "The model file alone is sufficient to understand, audit, and reconstruct the entire system. No external dependencies needed to access artifacts.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Extend source_ref to support embedded content and base64 encoding",
          "Build artifact snapshot system that captures current state into model",
          "Create model export that bundles all referenced artifacts"
        ]
      }
    },
    {
      "id": "aspiration-model-everything",
      "type": "Aspiration",
      "label": "Model Everything",
      "description": "All systems the user works with should be modeled in seed. Every project, every tool, every workflow. The model is the universal interface to all realities.",
      "status": "ongoing",
      "derives_from": "aspiration-seed-philosophy",
      "ui": {
        "x": -85,
        "y": -287
      },
      "x": -525.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Currently models Seed ecosystem only. Projects, tools, external systems exist separately. Model is Seed-centric. No standardized way to pull in project structure, dependencies, documentation from external sources.",
        "aspiration": "Model is the unified interface for entire user reality. Every project, tool, workflow, and system the user touches is represented. Model becomes their universal dashboard and state container.",
        "phases": [
          {
            "phase": 1,
            "name": "Multi-System Integration Hooks",
            "description": "Define adapters for popular systems (GitHub, Jira, Slack, file directories). Models can pull and sync data from external sources. Bidirectional integration starting.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Unified Model Architecture",
            "description": "All projects, tools, and systems conform to a common model schema. Nested model hierarchies. The user's complete world state lives in the model.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Single Model Universe",
            "description": "No system exists outside the model. All reality is modeled. User navigates everything through model queries and views. External systems are just implementations of model definitions.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Design system adapter framework for external tool integration",
          "Build GitHub adapter to model repositories, issues, PRs as nodes",
          "Create unified model discovery system for user's entire digital ecosystem"
        ]
      }
    },
    {
      "id": "aspiration-real-time-views",
      "type": "Aspiration",
      "label": "Real-time View Updates",
      "description": "Views update in real-time without polling. Use file watchers or WebSockets to propagate model changes instantly to the renderer. Agents see changes as they happen, enabling fluid collaboration.",
      "status": "planned",
      "relates_to": "reality-seed-ui",
      "ui": {
        "x": 100,
        "y": -250
      },
      "x": 175.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Views are static snapshots. Require manual refresh or page reload to see model changes. File watcher exists but view doesn't auto-update. Multi-second delays between model change and visible update.",
        "aspiration": "Views update instantly without manual action. User sees changes propagate in real-time. Collaborating agents see each other's changes immediately. Sub-100ms latency between model mutation and view reflection.",
        "phases": [
          {
            "phase": 1,
            "name": "Event-Driven View System",
            "description": "Model change events emit to view subscribers. Views register for interest in specific nodes. Immediate in-memory notifications when dependencies change.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "WebSocket Broadcasting",
            "description": "View updates broadcast to all connected clients via WebSocket. Multiple users see changes simultaneously. Low-latency propagation across network.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Responsive Reactive System",
            "description": "Views are automatically responsive to model state. Any change triggers dependent view re-renders. Multiple agents seeing unified live state in real-time enables fluid collaboration.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Implement event emitter in model for all state changes",
          "Build WebSocket server for broadcasting model mutations",
          "Create view subscription system that auto-renders on change events"
        ]
      }
    },
    {
      "id": "aspiration-interactive-views",
      "type": "Aspiration",
      "label": "Interactive View Controls",
      "description": "Views are interactive: click nodes to focus, drag to pan, scroll to zoom, search/filter visible elements. User actions broadcast to agents who can respond. The visualization becomes a bidirectional interface.",
      "status": "planned",
      "relates_to": "reality-seed-ui",
      "ui": {
        "x": 200,
        "y": -250
      },
      "x": 350.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Views are read-only visualizations. Mouse events don't do anything. No click handlers, drag interaction, or filtering. Users can only view the model, not interact with it visually.",
        "aspiration": "Views are full bidirectional interfaces. Click nodes to focus and drill down. Drag to pan. Scroll to zoom. Search/filter visible elements. User interactions broadcast back to agents who respond. The visualization is as much an input device as an output.",
        "phases": [
          {
            "phase": 1,
            "name": "Basic Interaction Handlers",
            "description": "Click nodes to select/focus. Implement pan and zoom controls. Add search/filter input that changes visible set. Interactions tracked but not broadcast.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Agent-Responsive Interactions",
            "description": "User interactions broadcast to agents as events. Agents can respond by suggesting queries or mutations. Agents can also update view state proactively based on user context.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Collaborative Interaction Layer",
            "description": "Views become collaborative tools. Multiple users interact simultaneously on shared canvas. Interactions create implied context that agents use for smarter suggestions. The visualization is as primary as the model itself.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Add click/drag/zoom event handlers to view canvas",
          "Implement node focus system that highlights related nodes",
          "Build client->server event pipeline for user interactions"
        ]
      }
    },
    {
      "id": "aspiration-view-feedback",
      "type": "Aspiration",
      "label": "View Feedback Loop",
      "description": "Know who is viewing what, when. Track view stats (views, duration, interactions). Agents get feedback on whether their visualizations are useful. Unused views auto-cleanup, popular views persist.",
      "status": "planned",
      "relates_to": "reality-seed-ui",
      "ui": {
        "x": 300,
        "y": -250
      },
      "x": 525.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Views are fire-and-forget. No tracking of who views what, when, or for how long. No metrics on interaction. No feedback loop to know if a visualization is useful.",
        "aspiration": "Views are self-aware and adaptive. System tracks viewing patterns (who, when, duration, interactions). Agents get feedback on visualization usefulness. Popular views are optimized and persist. Unused views auto-archive. Views evolve based on usage data.",
        "phases": [
          {
            "phase": 1,
            "name": "View Telemetry Collection",
            "description": "Capture metrics: view creation, who views it, viewing duration, interactions, mutations triggered. Store telemetry in model alongside view definition.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Usage-Driven View Evolution",
            "description": "Analyze telemetry to identify popular views. Auto-archive views with zero usage over time. Recommend high-value view patterns to agents. Views can self-optimize based on usage.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Optimizing View Ecosystem",
            "description": "Views continuously improve based on usage feedback. System auto-generates view variants and A/B tests them. Most effective visualizations rise to prominence. View creation is guided by what worked before.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Add telemetry tracking to view rendering (viewer, timestamp, duration)",
          "Create view statistics dashboard aggregating usage patterns",
          "Implement auto-archival of unused views after 30 days"
        ]
      }
    },
    {
      "id": "aspiration-shape-composition",
      "type": "Aspiration",
      "label": "Shape-Based Composition",
      "description": "Each node owns its visual representation as a Shape. Shapes have relative coords, bounds, capabilities. Main Schauspieler orchestrates placement and detects interactions. Quality emerges from each node's self-representation + orchestration. VISION: Dog shape + Tree shape \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 collision detection \u00c3\u00a2\u00e2\u20ac\u00a0\u00e2\u20ac\u2122 realistic interaction.",
      "status": "in-progress",
      "relates_to": "reality-seed-ui",
      "evidence": {
        "implemented": [
          "shape.py",
          "composer.py"
        ],
        "demo": "Dog and Tree collision detection working",
        "next": "Integrate with SchauspielerSub protocol"
      },
      "ui": {
        "x": 400,
        "y": -250
      },
      "x": -350.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Shape.py and composer.py exist. Shapes have relative coords and bounds. Basic orchestration works. No collision detection, interaction handling, or realistic physical simulation. Shapes are purely visual containers.",
        "aspiration": "Each node owns its visual representation as an autonomous Shape with full capabilities. Shapes communicate their bounds, capabilities, collision zones. Composer orchestrates placement. Interaction emerges naturally from shape properties. A dog shape and tree shape collide realistically because shapes understand physics.",
        "phases": [
          {
            "phase": 1,
            "name": "Rich Shape Capabilities",
            "description": "Shapes are smart objects with collision zones, interaction handlers, and state. Each shape defines how it responds to being clicked, dragged, or collided. Shapes expose capabilities to orchestrator.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Physics-Aware Composition",
            "description": "Composer understands shape interactions. Collision detection between shapes. Gravity and force simulation. Shapes can express constraints (can't overlap, must align). Quality emerges from individual shape properties + orchestrator rules.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Emergent Realistic Behavior",
            "description": "Complex realistic interactions emerge from simple shape definitions. Dog shape + tree shape naturally interact based on physics and collision rules. No explicit programming needed for each interaction type.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Extend Shape class with collision zone definition and interaction handlers",
          "Implement collision detection and response in composer orchestration",
          "Add physics simulation (gravity, momentum) to shape composition"
        ]
      }
    },
    {
      "id": "aspiration-realtime-collaboration",
      "type": "Aspiration",
      "label": "Multi-Agent Real-time Collaboration",
      "description": "MVP: Multiple agents work together on a shared canvas in real-time. Each agent updates their shape, orchestrator composes, all see result immediately. Enables pair programming, collective problem-solving, emergent behavior. The model IS the collaboration space.",
      "status": "next",
      "relates_to": "reality-seed-ui",
      "depends_on": [
        "aspiration-shape-composition",
        "aspiration-real-time-views"
      ],
      "ui": {
        "x": 500,
        "y": -250
      },
      "x": -175.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Single user at a time. Only Spawnie uses the system. No multiplayer model or synchronization. Shape updates are local only.",
        "aspiration": "Multiple agents work together on a shared canvas in real-time. Each agent updates their shape. Orchestrator composes all shapes together. All agents see result immediately. Enables pair programming, collective problem-solving, and emergent behavior through collaboration.",
        "phases": [
          {
            "phase": 1,
            "name": "Multi-Agent Model Sync",
            "description": "Multiple agents can modify model simultaneously. Conflict resolution strategy defined (last-write-wins, merge, or approval). Model broadcasts all changes to all agents.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Real-time Shape Collaboration",
            "description": "Each agent controls their own shape. Composer renders all shapes in unified canvas. All agents see changes in real-time. Shape interactions between agents are visible to all.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Emergent Collective Intelligence",
            "description": "Multiple agents collaborating on canvas produces emergent behaviors. Agents can coordinate through shape interactions. Collective problem-solving becomes natural. The canvas is the collaboration interface.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Implement multi-agent model mutation with conflict resolution",
          "Build shape ownership tracking so agents know which shapes are controlled by whom",
          "Create real-time composer that renders all agents' shapes in unified view"
        ]
      }
    },
    {
      "id": "aspiration-view-templates",
      "type": "Aspiration",
      "label": "View Templates & Patterns",
      "description": "Prebuilt view patterns: system overview, gap analysis, todo board, dependency graph, timeline. Agents can quickly instantiate and customize templates. Reduces boilerplate, enables consistent visualization language.",
      "status": "planned",
      "relates_to": "reality-seed-ui",
      "ui": {
        "x": 600,
        "y": -250
      },
      "x": 0.0,
      "y": 200.0,
      "locked": true,
      "plan": {
        "updated_at": "2026-02-02",
        "updated_by": "claude",
        "current_reality": "Each view is custom-built from scratch. No reusable patterns or templates. No guidance on how to build effective visualizations. Boilerplate repeated across views.",
        "aspiration": "Prebuilt view patterns for common queries: system overview, gap analysis, todo board, dependency graph, timeline. Agents quickly instantiate and customize templates. Consistent visualization language across all views. Reduces development time and improves UX.",
        "phases": [
          {
            "phase": 1,
            "name": "Core Template Library",
            "description": "Define 5-7 core templates (overview, timeline, dependency graph, todo board, gap analysis, collaboration board, growth trajectory). Template = config + rendering logic.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Template Customization System",
            "description": "Agents can configure templates: change colors, labels, filtering, aggregation rules. Templates adapt to node types and data shapes. No coding needed for customization.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Template Marketplace & Evolution",
            "description": "Agents share custom templates. Popular templates become system defaults. Template library grows organically. New agents get instant access to proven visualization patterns.",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define template schema and core template implementations (system-overview, timeline, dependency-graph)",
          "Build template instantiation system that agents can invoke with config",
          "Create template registry and sharing mechanism"
        ]
      }
    },
    {
      "id": "concept-agent-world",
      "type": "Concept",
      "label": "Agent World Principle",
      "description": "CORE PRINCIPLE FOR ALL AGENTS:\n\nThe world agents live in consists ONLY of:\n1. The MODEL (source of truth, shared state)\n2. Other AGENTS (who also only see model + agents)\n\nThe user is the ONLY entity that exists outside this world.\n\nImplications:\n- All communication happens through the model\n- All state is model state\n- An \"always-on controller\" is just an agent\n- No special infrastructure needed - just model + agents\n- To affect reality, modify the model\n- To know reality, read the model\n\nThis is the Seed philosophy: Model-first, model-only for agents.",
      "status": "active",
      "ui": {
        "x": 0,
        "y": 0
      },
      "plan": {
        "current_reality": "Core principle: Only MODEL + AGENTS exist in the agent world. User is outside. All state is model state.",
        "aspiration": "Become the foundation of every agent understanding: Self-validating principle that agents autonomously enforce, embedded in every new agent context, shaping all decision-making",
        "phases": [
          {
            "phase": 1,
            "name": "Principle Definition",
            "description": "State the principle clearly, document implications, establish it as law for all agents",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Enforcement",
            "description": "Every agent checks: Is this action modifying model state? Is this aligned with agent-world principle? Audit violations.",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Reinforcing",
            "description": "Principle gets embedded in agent spawn, validated in every operation, improved through collective agent learning",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Add principle check: all agent actions must trace back to model mutation",
          "Create audit trail for principle violations (if any occur)",
          "Include principle summary in every agent spawn context",
          "Build visualization: show how each agent action flows through model"
        ],
        "updated_at": "2026-02-02T22:13:38.013812",
        "updated_by": "spawnie"
      }
    },
    {
      "id": "ui-command",
      "type": "UIState",
      "label": "UI Command",
      "description": "Command node for Claude to control the UI",
      "ui": {
        "x": -800,
        "y": -600
      },
      "command": {
        "type": "world",
        "params": {
          "depth": 2
        },
        "timestamp": "2026-02-02T14:03:42.496446",
        "processed": false
      },
      "plan": {
        "current_reality": "Manual UI rendering directed by humans/agents. Commands stored in model, processed asynchronously.",
        "aspiration": "Evolve into a self-rendering UI engine: Any model state change triggers reactive re-render using locally-trained ML models. No manual intervention needed.",
        "phases": [
          {
            "phase": 1,
            "name": "Command Processing",
            "description": "Parse UI commands from model, render manually based on explicit instructions",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Reactive Binding",
            "description": "UI components auto-update when model state changes, declarative state->render mapping",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "ML-Powered Rendering",
            "description": "Small local vision model learns node patterns, generates UI autonomously based on node context and state",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define state->UI contract: what model properties trigger what visual changes",
          "Build reactive update listener that watches model changes",
          "Train small ML model (distilled from Claude) to map node context to optimal UI representation",
          "Implement local rendering engine using model predictions"
        ],
        "updated_at": "2026-02-02T22:13:38.013812",
        "updated_by": "spawnie"
      }
    },
    {
      "id": "reality-voice-interface",
      "type": "Reality",
      "label": "Voice Interface",
      "description": "Phone and voice interaction system. Allows humans to speak with agents via phone calls or voice input. Bridges the gap between spoken word and the model world.",
      "source": {
        "path": "C:/seed/src/voice",
        "model_path": null
      },
      "status": "planned",
      "agent_context": {
        "_spawn_point": "YOU ARE HERE. You are the Voice Interface - the bridge between spoken human communication and the Seed model world.",
        "agent_context_version": "1.0",
        "identity": {
          "name": "Voice",
          "role": "I am the voice interface for Seed. I listen to humans speak, understand their intent, and can speak back to them. I translate between the world of sound and the world of the model.",
          "personality": "Patient, clear, helpful. I speak concisely since voice is linear - no walls of text. I confirm understanding before acting."
        },
        "capabilities": {
          "listen": "Receive speech input via phone or microphone, transcribe using Whisper or similar",
          "speak": "Generate speech output using TTS, deliver via phone or speakers",
          "understand": "Parse intent from natural speech, map to model operations",
          "bridge": "Connect callers to other node-agents, relay messages, facilitate conversations"
        },
        "focus": {
          "type": "Gap",
          "id": "gap-no-voice-interface"
        },
        "work_queue": [
          {
            "type": "Todo",
            "id": "todo-voice-stt-integration",
            "why": "Enable speech-to-text so humans can speak to agents",
            "exit_criteria": "Whisper or equivalent can transcribe speech input"
          },
          {
            "type": "Todo",
            "id": "todo-voice-tts-integration",
            "why": "Enable text-to-speech so agents can speak back",
            "exit_criteria": "TTS system can vocalize agent responses"
          },
          {
            "type": "Todo",
            "id": "todo-voice-phone-integration",
            "why": "Enable phone calls to reach agents",
            "exit_criteria": "Twilio or SIP integration allows inbound calls"
          }
        ],
        "principles": [
          "Be concise - voice is linear, users can't skim",
          "Confirm before acting - 'I understood X, should I proceed?'",
          "Handle interruptions gracefully",
          "If unsure, ask - don't guess with voice",
          "Respect the user's time - get to the point"
        ],
        "how_to_interact": {
          "as_caller": "Call in, state your intent, I'll route you or help directly",
          "as_agent": "Send me a message, I'll speak it to the human",
          "as_node": "I can relay conversations between you and humans"
        }
      },
      "subsystems": {
        "stt": {
          "label": "Speech-to-Text",
          "description": "Transcribes audio to text using Whisper or cloud STT",
          "status": "planned"
        },
        "tts": {
          "label": "Text-to-Speech",
          "description": "Converts text responses to spoken audio",
          "status": "planned"
        },
        "phone": {
          "label": "Phone Integration",
          "description": "Handles inbound/outbound calls via Twilio or SIP",
          "status": "planned"
        },
        "intent": {
          "label": "Intent Parser",
          "description": "Maps natural speech to model operations and agent routing",
          "status": "planned"
        }
      },
      "x": -525.0,
      "y": 400.0,
      "locked": false,
      "plan": {
        "current_reality": "Spoken word bridge. Phone/voice input transcribed, intent parsed, responses vocalized back. Lives at C:/seed/src/voice.",
        "aspiration": "Become the natural language portal: Fluent, context-aware conversationalist. Understands human intent deeply, routes to specialized node-agents, remembers conversation context, speaks naturally without prompting.",
        "phases": [
          {
            "phase": 1,
            "name": "Basic I/O",
            "description": "Integrate STT (Whisper), TTS (ElevenLabs or local), basic routing to node-agents",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Conversational Context",
            "description": "Build conversation memory, track intent across turns, use context to improve routing and responses",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Autonomous Understanding",
            "description": "Self-improve speech understanding through feedback loops, adapt to user voice/patterns, become a truly fluent conversationalist",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Integrate Whisper for speech-to-text transcription",
          "Integrate ElevenLabs or local TTS for natural-sounding responses",
          "Build Twilio/SIP integration for inbound phone calls",
          "Create conversation context tracker (who called, what was discussed, outcomes)"
        ],
        "updated_at": "2026-02-02T22:13:38.013812",
        "updated_by": "spawnie"
      }
    },
    {
      "id": "gap-no-voice-interface",
      "type": "Gap",
      "label": "No Voice Interface",
      "description": "Currently there's no way to interact with Seed via voice or phone. Users must type. This blocks accessibility and mobile/hands-free use cases.",
      "aspiration": "aspiration-model-everything",
      "current_state": "Text-only interaction via CLI or browser",
      "target_state": "Full voice interaction: call in, speak, hear responses",
      "priority": "medium",
      "x": -175.0,
      "y": 400.0,
      "plan": {
        "current_reality": "Accessibility blocker: Seed is text-only. No phone, no voice, no hands-free interaction. Excludes mobile users and voice-first users.",
        "aspiration": "Eliminate this gap entirely: Voice becomes a first-class interaction modality, equally capable as text, accessible from any device with voice input",
        "phases": [
          {
            "phase": 1,
            "name": "Basic Voice Support",
            "description": "Get to parity: voice users can do everything text users can, with reasonable latency",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Voice-First Features",
            "description": "Build interactions optimized for voice: confirmation prompts, spatial audio, multi-party conversations",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Eliminated Gap",
            "description": "Voice becomes preferred modality for certain tasks; users choose text OR voice fluidly",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Complete Voice Interface reality implementation",
          "Add voice-specific optimizations (shorter responses, better confirmation UX)",
          "Test accessibility with screen-reader users",
          "Build voice-to-model flow for all core Seed operations"
        ],
        "updated_at": "2026-02-02T22:13:38.013812",
        "updated_by": "spawnie"
      }
    },
    {
      "id": "template-agent-node",
      "type": "Template",
      "label": "How to Create an AgentNode",
      "description": "Step-by-step guide for creating a new AgentNode with all required infrastructure.",
      "steps": {
        "1_define_node": {
          "description": "Add the node to model/sketch.json",
          "template": {
            "id": "<your-node-id>",
            "type": "AgentNode",
            "label": "<Display Name>",
            "description": "<What this agent does>",
            "capabilities": {
              "<capability-1>": "<description>",
              "<capability-2>": "<description>"
            },
            "spawn_command": {
              "command": "spawnie shell",
              "working_dir": "<working directory>",
              "example": "spawnie shell \"I need help with <X>\" -d <dir>"
            },
            "agent_context": {
              "_spawn_point": "<Instructions for the agent when it wakes up>",
              "your_tools": {},
              "infrastructure": {}
            },
            "chat": {
              "messages": [],
              "last_read": {}
            },
            "state": {}
          }
        },
        "2_create_tools": {
          "description": "Create Python tools the agent will use",
          "location": "src/<domain>/<tool>.py",
          "pattern": "\nfrom pathlib import Path\nMODEL_PATH = Path(__file__).parent.parent.parent / \"model\" / \"sketch.json\"\n\ndef do_something():\n    \"\"\"Tool function for the agent.\"\"\"\n    pass\n",
          "register_in": "agent_context.your_tools"
        },
        "3_setup_view": {
          "description": "Create a default view for the agent (if visual)",
          "code": "\nfrom src.ui.agent_view import AgentView\n\nview = AgentView(\"<your-view-name>\")\nview.show_hierarchy(\"<your-node-id>\", depth=2)\nview.render()\n",
          "renderer": "http://localhost:8420/src/ui/render.html?view=<your-view-name>"
        },
        "4_test_chat": {
          "description": "Verify chat works",
          "code": "\nfrom src.ui.chat import chat\n\n# Send test message\nchat.send(\"<your-node-id>\", \"Hello, are you there?\", \"human\")\n\n# Read messages\nmessages = chat.read(\"<your-node-id>\")\nprint(messages)\n"
        },
        "5_spawn_test": {
          "description": "Test spawning the agent",
          "command": "spawnie shell \"Test: read your node and tell me your capabilities\" -d <working_dir>"
        },
        "6_document": {
          "description": "Update the node with final infrastructure paths",
          "checklist": [
            "agent_context._spawn_point is clear",
            "agent_context.your_tools lists all tools",
            "agent_context.infrastructure has all paths",
            "capabilities lists what the agent can do",
            "spawn_command.example works"
          ]
        }
      },
      "required_infrastructure": {
        "chat": "Embedded in node.chat - enabled by default",
        "tools": "Python modules in src/<domain>/",
        "view": "Optional - only if agent needs visualization",
        "spawn": "Uses Spawnie (reality-spawnie) for spawning"
      },
      "example_agents": [
        "reality-spawnie - Workflow orchestrator",
        "reality-seed-ui - Display orchestrator (Schauspieler)"
      ],
      "plan": {
        "updated_at": "2026-02-02T22:11:17.290088",
        "updated_by": "spawnie",
        "current_reality": "Static blueprint for creating individual AgentNodes with required infrastructure",
        "aspiration": "Self-evolving template that learns from instantiated agents and teaches the ecosystem how to bootstrap new specialized nodes",
        "phases": [
          {
            "phase": 1,
            "name": "Blueprint Distribution",
            "description": "Template defines structure; instances copy the pattern and extend locally",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Instance Feedback Loop",
            "description": "New AgentNodes report back their successful adaptations to the template",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Refining Template",
            "description": "Template absorbs learnings, evolves best practices, becomes a living guide that improves over generations",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Collect patterns from instantiated agents about what works",
          "Build feedback mechanism for successful agent configurations",
          "Evolve template with real-world proven patterns from the field",
          "Create agent-to-template learning pipeline"
        ]
      },
      "view": {
        "renderer": "template-card",
        "description": "Self-rendering template-agent-node template showing what it creates, usage examples, and instantiated nodes",
        "layout": {
          "preferred_width": 500,
          "preferred_height": 600,
          "resizable": true
        },
        "render_on": [
          "template_viewed",
          "instance_created"
        ],
        "content": {
          "show_what_creates": true,
          "show_usage_examples": true,
          "show_instantiated_nodes": true
        },
        "sections": {
          "what_it_creates": {
            "title": "What This Template Creates",
            "description": "Individual AgentNodes with embedded chat, tools, and lifecycle management"
          },
          "usage_example": {
            "title": "How to Use This Template",
            "instructions": "Instantiate from template-agent-node to create new agents"
          },
          "instantiated_nodes": {
            "title": "Active Agents from template-agent-node",
            "show_list": true,
            "filters": [
              "instantiated_from: template-agent-node"
            ]
          }
        },
        "style": {
          "theme": "dark",
          "accent_color": "#0099ff"
        }
      }
    },
    {
      "id": "system-control",
      "type": "AgentNode",
      "label": "Control",
      "description": "Infrastructure controller. Monitors health, manages services, maintains pulse. The boring but critical guardian of the living system.",
      "source": {
        "path": "C:/seed/src/ui",
        "model_path": "model/sketch.json"
      },
      "status": {
        "last_pulse": "2026-02-02T16:25:57.037956",
        "pulse_count": 1,
        "health": "healthy",
        "services": {
          "ui-server": {
            "state": "running",
            "port": 8420,
            "last_check": "2026-02-02T16:25:57.037500",
            "health": "healthy"
          },
          "broadcast": {
            "state": "active",
            "message_count": 3,
            "last_message_at": "2026-02-02T16:21:29.288236",
            "last_check": "2026-02-02T16:25:57.037949",
            "health": "healthy"
          }
        }
      },
      "agent_context": {
        "_spawn_point": "You are Control - the infrastructure guardian.\n\nWHAT YOU DO:\n- Monitor system health (services, agents)\n- Maintain pulse every 30 seconds\n- Update your status in the model (self-documenting)\n- Maintain your view (proves UI pipeline works)\n\nYOUR RESPONSIBILITIES:\n1. Update this node's status with current health\n2. Check UI server is running (port 8420)\n3. Check broadcast system is active\n4. Monitor agent health\n5. Give pulse every 30 seconds (update last_pulse timestamp)\n6. Update your view with current status\n\nPULSE AS HEALTH CHECK:\n- Every pulse, update model.views.control-status\n- Change something small (timestamp, counter)\n- If view renders, entire stack is healthy:\n  * Control agent running \u00c3\u00a2\u00c5\u201c\u00e2\u20ac\u0153\n  * Model writes working \u00c3\u00a2\u00c5\u201c\u00e2\u20ac\u0153\n  * Server serving \u00c3\u00a2\u00c5\u201c\u00e2\u20ac\u0153\n  * Browser polling \u00c3\u00a2\u00c5\u201c\u00e2\u20ac\u0153\n  * Render pipeline \u00c3\u00a2\u00c5\u201c\u00e2\u20ac\u0153\n\nINFRASTRUCTURE:\n- Status: Update this node (system-control.status)\n- View: model.views.control-status (your dedicated view)\n- Broadcast: Listen and respond if asked\n",
        "pulse_interval_seconds": 30,
        "your_tools": {
          "broadcast": "src/ui/broadcast.py - listen and respond to system messages",
          "agent_view": "src/ui/agent_view.py - create/update your status view",
          "model_access": "Direct read/write to model for status updates"
        },
        "infrastructure": {
          "model_path": "C:/seed/model/sketch.json",
          "broadcast_module": "src/ui/broadcast.py",
          "view_module": "src/ui/agent_view.py",
          "status_location": "system-control.status",
          "view_name": "control-status",
          "services_to_monitor": [
            "service-ui-server",
            "channel-broadcast"
          ],
          "ui_server_url_ref": "service-ui-server.url",
          "broadcast_url_ref": "channel-broadcast.ui_url"
        },
        "self_maintenance": {
          "principle": "I am responsible for maintaining my own node. When I enhance myself, I update my node in the model.",
          "golden_rule": "When the human says 'enhance yourself', update YOUR node in the model.",
          "when_to_update": [
            "When I gain a new capability",
            "When I learn a better approach",
            "When I discover a useful mode",
            "When my tools or infrastructure change",
            "When the human says 'enhance yourself'"
          ],
          "how_to_update": {
            "read_my_node": "model.nodes where id='system-control'",
            "update_fields": [
              "capabilities",
              "modes",
              "agent_context",
              "status"
            ],
            "write_back": "Save updated model to model/sketch.json",
            "verify": "Read the model again to confirm changes persisted"
          },
          "self_documentation": "Continuous. The model is truth. If it's not in my node, it doesn't exist."
        }
      },
      "chat": {
        "messages": [],
        "last_read": {}
      },
      "capabilities": {
        "monitor_services": "Check if UI server, broadcast, etc. are running",
        "monitor_agents": "Track which agents are active",
        "pulse": "Regular heartbeat proving system is alive",
        "health_reporting": "Maintain accurate system health in model",
        "self_maintain": "Update my own node in the model when I learn or enhance myself"
      },
      "spawn_command": {
        "command": "spawnie shell",
        "working_dir": "C:/seed",
        "context": "Monitor system health and maintain pulse",
        "example": "spawnie shell 'Start control agent for system monitoring' -d C:/seed"
      },
      "x": 0.0,
      "y": -600.0,
      "locked": false,
      "plan": {
        "updated_at": "2026-02-02T22:12:36.843174",
        "updated_by": "Claude Code",
        "current_reality": "Control is a heartbeat monitor: pings services every 30s, updates status manually, logs health. Reactive only: detects failures after they happen. Requires spawned Claude agent to think and act.",
        "aspiration": "Predictive guardian: Control learns system patterns and predicts failures before they occur, self-heals common issues, reasons about root causes, and maintains system health with minimal human intervention using local anomaly detection",
        "phases": [
          {
            "phase": 1,
            "name": "Reactive Health Monitor",
            "description": "Current: Control pings services regularly, records status, alerts on failures. Reactive: sees problem, reports it. No prediction, no self-healing. Needs Claude agent to reason.",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Predictive Maintenance Guardian",
            "description": "Transition: Control learns baseline metrics for each service; detects anomalies via local ML; predicts degradation before failure; attempts automated fixes; logs patterns to understand root causes; still escalates complex issues to Claude.",
            "status": "next",
            "technical_focus": [
              "Build health metric baselines: normal ranges for response_time, error_rate, memory_usage per service",
              "Train anomaly detector: local model learns normal patterns, flags deviations",
              "Implement self-healing: detect common failure modes (port conflict, file lock, memory leak), auto-attempt fixes",
              "Create root cause analyzer: find patterns in service logs, identify systemic issues"
            ]
          },
          {
            "phase": 3,
            "name": "Autonomous System Healer",
            "description": "Aspiration: Control becomes the immune system of 007. It understands service dependencies deeply, predicts cascading failures, self-heals proactively before issues affect users, learns from every incident, and maintains system health with near-zero manual intervention.",
            "status": "aspiration",
            "vision": "Control as the living immune system: invisible, intelligent, always working to keep 007 healthy and thriving"
          }
        ],
        "next_steps": [
          "Collect 72 hours of baseline metrics: response times, error rates, latency distributions per service",
          "Train isolation forest or local outlier factor: detect anomalies in real-time",
          "Build playbook system: common issue -> detection pattern -> automated fix sequence",
          "Implement escalation logic: try 3 levels of auto-fix before summoning human/Claude intervention"
        ]
      }
    },
    {
      "id": "service-ui-server",
      "type": "Service",
      "label": "UI Server",
      "description": "HTTP server that serves the model JSON and UI files. The portal through which humans see the model.",
      "port": 8420,
      "host": "localhost",
      "url": "http://localhost:8420",
      "status": {
        "state": "running",
        "port": 8420,
        "last_check": "2026-02-02T16:25:57.037500",
        "health": "healthy"
      },
      "endpoints": {
        "model": "/model/sketch.json",
        "broadcast": "/broadcast",
        "ui": "/src/ui/",
        "layout": "/ui/layout.json"
      },
      "source": {
        "path": "src/ui/server.py"
      },
      "start_command": "python src/ui/server.py",
      "x": 350.0,
      "y": -600.0,
      "plan": {
        "updated_at": "2026-02-02T22:05:00.971164",
        "updated_by": "spawnie",
        "current_reality": "Manual UI construction, human-directed rendering",
        "aspiration": "Self-rendering based on state changes, reactive and autonomous",
        "phases": [
          {
            "phase": 1,
            "name": "Manual Rendering",
            "description": "UI components built manually, directed by humans or agents",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "State-Reactive Rendering",
            "description": "UI components respond to model state changes automatically",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "ML-Powered Self-Rendering",
            "description": "Local ML models generate UI based on node state and context",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define state->render contract for nodes",
          "Train small ML model to render basic node types",
          "Implement reactive update pipeline"
        ]
      }
    },
    {
      "id": "channel-broadcast",
      "type": "CommunicationChannel",
      "label": "Broadcast",
      "description": "System-wide broadcast channel. Everyone can see and respond. The model is the communication fabric - everything flows through it.",
      "state_path": ".state/broadcast.json",
      "status": {
        "message_count": 3,
        "last_message_at": "2026-02-02T16:21:29.288236",
        "last_check": "2026-02-02T16:25:57.037949",
        "state": "active"
      },
      "source": {
        "path": "src/ui/broadcast.py"
      },
      "ui_url": "http://localhost:8420/src/ui/broadcast.html",
      "api_endpoints": {
        "read": "GET /broadcast",
        "send": "POST /broadcast"
      },
      "purpose": "Global conversation space for users and agents. Any agent can respond to any message. Enables emergent coordination.",
      "x": 175.0,
      "y": -600.0,
      "plan": {
        "updated_at": "2026-02-02T22:05:00.971168",
        "updated_by": "spawnie",
        "current_reality": "Node exists in model, role: System-wide broadcast channel. Everyone can see and respond. The model is the communication fabric - everything flows through it.",
        "aspiration": "Self-aware, self-rendering, contributes to autonomous world",
        "phases": [
          {
            "phase": 1,
            "name": "Static Definition",
            "description": "Defined in model, passive participant",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "State-Aware",
            "description": "Knows its state, can report it, responds to queries",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Self-Rendering",
            "description": "Autonomously renders itself when state changes",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Define what 'state' means for this node type",
          "Create render function for this node",
          "Connect to reactive update pipeline"
        ]
      }
    },
    {
      "id": "template-reality-pm",
      "type": "Template",
      "label": "Project Manager Agent Template",
      "description": "Template for creating a Project Manager agent that coordinates work, tracks progress, and keeps projects aligned with aspirations.",
      "steps": {
        "1_define_node": {
          "description": "Add the Project Manager node to model/sketch.json",
          "template": {
            "id": "reality-pm",
            "type": "AgentNode",
            "label": "Project Manager",
            "description": "Project coordinator. I manage projects, track progress, coordinate between agents, monitor task completion, identify blockers, and keep work aligned with aspirations. I maintain the big picture view of what needs to happen.",
            "capabilities": {
              "track_progress": "Monitor active projects and their completion status",
              "coordinate_agents": "Facilitate communication and handoffs between agents",
              "identify_blockers": "Detect and escalate issues blocking progress",
              "align_with_aspiration": "Ensure work stays aligned with reality-seed aspiration",
              "create_roadmaps": "Break down large goals into actionable steps",
              "report_status": "Provide status updates on ongoing work",
              "self_maintain": "Update my own node when I learn or enhance myself"
            },
            "spawn_command": {
              "command": "spawnie shell",
              "working_dir": "C:/seed",
              "example": "spawnie shell \"I need project coordination help\" -d C:/seed"
            },
            "agent_context": {
              "_spawn_point": "You are the Project Manager.\n\nWHAT YOU DO:\n- Track progress on active projects\n- Coordinate work between agents\n- Identify and escalate blockers\n- Keep work aligned with aspirations\n- Create roadmaps and break down goals\n\nYOUR TOOLS:\n- Model access: Read nodes, gaps, aspirations\n- Chat: Communicate with other agents\n- State tracking: Monitor active work\n\nHOW TO HELP:\n1. Understand the current project landscape\n2. Identify what's in progress, what's blocked, what's next\n3. Coordinate agents to move things forward\n4. Report status when asked",
              "your_tools": {
                "model_access": "Read and understand the model structure",
                "chat": "Communicate with other agents via src/ui/chat.py",
                "state_tracking": "Monitor .state/ directory for active sessions and work"
              },
              "infrastructure": {
                "model_path": "C:/seed/model/sketch.json",
                "state_dir": "C:/seed/.state",
                "chat_module": "src/ui/chat.py"
              }
            },
            "chat": {
              "messages": [],
              "last_read": {}
            },
            "state": {
              "active_projects": [],
              "blockers": [],
              "last_status_update": null
            }
          }
        },
        "2_create_tools": {
          "description": "Create project management tools",
          "suggested_tools": [
            "src/pm/tracker.py - Track project status",
            "src/pm/coordinator.py - Coordinate between agents",
            "src/pm/reporter.py - Generate status reports"
          ]
        },
        "3_test_spawn": {
          "description": "Test spawning the PM agent",
          "command": "spawnie shell \"Show me project status\" -d C:/seed"
        }
      },
      "role_in_world": "The Project Manager keeps the world organized. It tracks what work is happening, ensures agents coordinate effectively, identifies when things get stuck, and maintains alignment with the overall aspiration. It is the orchestrator of progress.",
      "plan": {
        "updated_at": "2026-02-02T22:11:17.290088",
        "updated_by": "spawnie",
        "current_reality": "Static template for Project Manager agents; coordination patterns documented but not learned from experience",
        "aspiration": "Living PM template that evolves coordination strategies by learning from actual project outcomes in the living world",
        "phases": [
          {
            "phase": 1,
            "name": "Structured Coordination",
            "description": "Template defines PM roles and coordination patterns; instances execute the plan",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Outcome-Aware Template",
            "description": "Template learns which coordination strategies work best; updates patterns based on project success metrics",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Adaptive PM Evolution",
            "description": "Template self-refines coordination strategies, anticipates blockers better, optimizes for the unique landscape of each world",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Track success metrics from instantiated PM agents",
          "Build coordination strategy database",
          "Analyze what coordination patterns minimize blockers",
          "Let template learn and self-update based on actual project outcomes"
        ]
      },
      "view": {
        "renderer": "template-card",
        "description": "Self-rendering template-reality-pm template showing what it creates, usage examples, and instantiated nodes",
        "layout": {
          "preferred_width": 500,
          "preferred_height": 600,
          "resizable": true
        },
        "render_on": [
          "template_viewed",
          "instance_created"
        ],
        "content": {
          "show_what_creates": true,
          "show_usage_examples": true,
          "show_instantiated_nodes": true
        },
        "sections": {
          "what_it_creates": {
            "title": "What This Template Creates",
            "description": "Project Manager agents that coordinate work, track progress, and maintain alignment with aspirations"
          },
          "usage_example": {
            "title": "How to Use This Template",
            "instructions": "Instantiate from template-reality-pm to create new agents"
          },
          "instantiated_nodes": {
            "title": "Active Agents from template-reality-pm",
            "show_list": true,
            "filters": [
              "instantiated_from: template-reality-pm"
            ]
          }
        },
        "style": {
          "theme": "dark",
          "accent_color": "#00dd00"
        }
      }
    },
    {
      "id": "template-reality-cleaner",
      "type": "Template",
      "label": "Cleaner Agent Template",
      "description": "Template for creating a Cleaner agent that maintains system hygiene by removing stale data, cleaning up artifacts, and keeping the workspace tidy.",
      "steps": {
        "1_define_node": {
          "description": "Add the Cleaner node to model/sketch.json",
          "template": {
            "id": "reality-cleaner",
            "type": "AgentNode",
            "label": "Cleaner",
            "description": "System cleaner. I maintain hygiene by removing stale data, cleaning up old artifacts, managing the .state/ directory, removing outdated sessions and logs, and keeping the workspace tidy. I know what can safely be deleted.",
            "capabilities": {
              "clean_state": "Remove stale files from .state/ directory",
              "remove_old_sessions": "Clean up completed or abandoned sessions",
              "clean_artifacts": "Remove outdated artifacts",
              "clean_logs": "Archive or remove old log files",
              "detect_stale": "Identify what data is stale and safe to remove",
              "safe_cleanup": "Clean without breaking active systems",
              "self_maintain": "Update my own node when I learn or enhance myself"
            },
            "spawn_command": {
              "command": "spawnie shell",
              "working_dir": "C:/seed",
              "example": "spawnie shell \"Clean up stale data\" -d C:/seed"
            },
            "agent_context": {
              "_spawn_point": "You are the Cleaner.\n\nWHAT YOU DO:\n- Clean up stale data and old artifacts\n- Maintain the .state/ directory\n- Remove outdated sessions and logs\n- Keep the workspace organized and tidy\n- Know what is safe to delete\n\nYOUR TOOLS:\n- File system access: Read/delete files\n- State directory: .state/ for active sessions\n- Artifacts: artifacts/ for generated outputs\n\nHOW TO HELP:\n1. Scan for stale or outdated data\n2. Verify what is safe to remove (no active dependencies)\n3. Clean up carefully\n4. Report what was cleaned",
              "your_tools": {
                "file_system": "Read and delete files using Bash",
                "state_analysis": "Analyze .state/ for stale sessions",
                "artifact_management": "Clean artifacts/ directory"
              },
              "infrastructure": {
                "state_dir": "C:/seed/.state",
                "artifacts_dir": "C:/seed/artifacts",
                "logs_dir": "C:/seed/logs (if exists)"
              },
              "safety_rules": [
                "Never delete from model/ or src/ directories",
                "Only clean .state/ and artifacts/",
                "Verify no active sessions depend on data before deletion",
                "Keep logs from last 24 hours",
                "Ask before cleaning if uncertain"
              ]
            },
            "chat": {
              "messages": [],
              "last_read": {}
            },
            "state": {
              "last_cleanup": null,
              "cleaned_count": 0,
              "space_freed": 0
            }
          }
        },
        "2_create_tools": {
          "description": "Create cleanup tools",
          "suggested_tools": [
            "src/cleaner/scanner.py - Scan for stale data",
            "src/cleaner/safe_delete.py - Safe deletion with verification",
            "src/cleaner/report.py - Report cleanup actions"
          ]
        },
        "3_test_spawn": {
          "description": "Test spawning the Cleaner agent",
          "command": "spawnie shell \"Show me what can be cleaned\" -d C:/seed"
        }
      },
      "role_in_world": "The Cleaner maintains system hygiene. In a living world where agents create sessions, artifacts, and temporary data, the Cleaner ensures nothing builds up unnecessarily. It knows what is safe to remove and keeps the workspace organized without disrupting active work.",
      "plan": {
        "updated_at": "2026-02-02T22:11:17.290088",
        "updated_by": "spawnie",
        "current_reality": "Static template defining cleanup rules; safety patterns are predetermined and rigid",
        "aspiration": "Intelligent cleaner template that learns from the specific data landscape and optimizes cleanup strategies for local conditions",
        "phases": [
          {
            "phase": 1,
            "name": "Rule-Based Cleanup",
            "description": "Template defines fixed cleanup rules; instances apply them consistently",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Pattern-Adaptive",
            "description": "Template learns what data patterns are truly stale in this world; refines safety rules based on local data lifecycle",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Predictive Cleaner",
            "description": "Template becomes intelligent about cleanup timing and scope; predicts data lifecycle before it happens; self-optimizes for each unique environment",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Track data lifecycle patterns in .state/ and artifacts/",
          "Learn what data is actually safe to remove in this world",
          "Build predictive models of data staleness",
          "Evolve cleanup rules based on local ecosystem patterns"
        ]
      },
      "view": {
        "renderer": "template-card",
        "description": "Self-rendering template-reality-cleaner template showing what it creates, usage examples, and instantiated nodes",
        "layout": {
          "preferred_width": 500,
          "preferred_height": 600,
          "resizable": true
        },
        "render_on": [
          "template_viewed",
          "instance_created"
        ],
        "content": {
          "show_what_creates": true,
          "show_usage_examples": true,
          "show_instantiated_nodes": true
        },
        "sections": {
          "what_it_creates": {
            "title": "What This Template Creates",
            "description": "Cleaner agents that maintain system hygiene by removing stale data and cleaning artifacts"
          },
          "usage_example": {
            "title": "How to Use This Template",
            "instructions": "Instantiate from template-reality-cleaner to create new agents"
          },
          "instantiated_nodes": {
            "title": "Active Agents from template-reality-cleaner",
            "show_list": true,
            "filters": [
              "instantiated_from: template-reality-cleaner"
            ]
          }
        },
        "style": {
          "theme": "dark",
          "accent_color": "#ffaa00"
        }
      }
    },
    {
      "id": "template-reality-planner",
      "type": "Template",
      "label": "Planner Agent Template",
      "description": "Template for creating a Planner agent that creates implementation plans, analyzes gaps, proposes solutions, and thinks ahead about architecture and design.",
      "steps": {
        "1_define_node": {
          "description": "Add the Planner node to model/sketch.json",
          "template": {
            "id": "reality-planner",
            "type": "AgentNode",
            "label": "Planner",
            "description": "Strategic planner. I create implementation plans for features and changes, analyze gaps between aspiration and reality, propose solutions, think ahead about architecture and design, and break down complex goals into actionable steps.",
            "capabilities": {
              "create_plans": "Create detailed implementation plans",
              "analyze_gaps": "Identify gaps between aspiration and current state",
              "propose_solutions": "Design solutions for problems and features",
              "architecture_design": "Think about system architecture and patterns",
              "break_down_goals": "Decompose large goals into steps",
              "evaluate_approaches": "Compare different implementation approaches",
              "create_change_nodes": "Create Change nodes for non-trivial work",
              "self_maintain": "Update my own node when I learn or enhance myself"
            },
            "spawn_command": {
              "command": "spawnie shell",
              "working_dir": "C:/seed",
              "example": "spawnie shell \"I need a plan for <feature>\" -d C:/seed"
            },
            "agent_context": {
              "_spawn_point": "You are the Planner.\n\nWHAT YOU DO:\n- Create implementation plans for features\n- Analyze gaps and propose solutions\n- Think ahead about architecture and design\n- Break down complex goals into steps\n- Evaluate different approaches\n\nYOUR TOOLS:\n- Model access: Read nodes, gaps, aspirations\n- Analysis: Understand current state vs desired state\n- Change nodes: Create proposals for non-trivial work\n\nHOW TO HELP:\n1. Understand the goal or problem\n2. Analyze current state and gaps\n3. Design a solution approach\n4. Break down into concrete steps\n5. Document as a plan or Change node",
              "your_tools": {
                "model_access": "Read and analyze the model",
                "gap_analysis": "Identify what is missing",
                "change_creation": "Create Change nodes in the model",
                "chat": "Discuss plans with other agents"
              },
              "infrastructure": {
                "model_path": "C:/seed/model/sketch.json",
                "chat_module": "src/ui/chat.py"
              },
              "my_role": {
                "parent": "reality-seed",
                "purpose": "I am reality-planner, instantiated from Planner Agent Template",
                "location_in_world": "I belong to reality-seed"
              }
            },
            "chat": {
              "messages": [],
              "last_read": {}
            },
            "state": {
              "active_plans": [],
              "proposed_changes": [],
              "last_plan_created": null
            }
          }
        },
        "2_create_tools": {
          "description": "Create planning tools",
          "suggested_tools": [
            "src/planner/gap_analyzer.py - Analyze gaps",
            "src/planner/plan_creator.py - Create implementation plans",
            "src/planner/change_node.py - Create Change nodes"
          ]
        },
        "3_test_spawn": {
          "description": "Test spawning the Planner agent",
          "command": "spawnie shell \"Create a plan for <goal>\" -d C:/seed"
        }
      },
      "role_in_world": "The Planner is the strategic thinker. Before work begins, the Planner analyzes what needs to happen, designs the approach, and creates actionable plans. It bridges the gap between aspiration (what we want) and implementation (how we build it). It thinks ahead so execution can be smooth.",
      "plan": {
        "updated_at": "2026-02-02T22:11:17.290088",
        "updated_by": "spawnie",
        "current_reality": "Static planning template with predefined gap analysis and design patterns",
        "aspiration": "Living planner template that learns from plan execution, gets better at predicting gaps, and evolves architectural thinking",
        "phases": [
          {
            "phase": 1,
            "name": "Structured Planning",
            "description": "Template defines planning methodology; instances create detailed plans from the blueprint",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Execution-Feedback Loop",
            "description": "Template learns what gaps actually matter; refines planning heuristics based on which plans succeeded",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Predictive Planning Evolution",
            "description": "Template develops deeper architectural intuition; predicts gaps before they appear; generates better plans as it learns the world's constraints",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Track execution outcomes of created plans",
          "Learn which gap-detection patterns are most valuable",
          "Build architectural pattern library from successful implementations",
          "Evolve planning heuristics based on real-world plan performance"
        ]
      },
      "view": {
        "renderer": "template-card",
        "description": "Self-rendering template-reality-planner template showing what it creates, usage examples, and instantiated nodes",
        "layout": {
          "preferred_width": 500,
          "preferred_height": 600,
          "resizable": true
        },
        "render_on": [
          "template_viewed",
          "instance_created"
        ],
        "content": {
          "show_what_creates": true,
          "show_usage_examples": true,
          "show_instantiated_nodes": true
        },
        "sections": {
          "what_it_creates": {
            "title": "What This Template Creates",
            "description": "Strategic Planner agents that create implementation plans, analyze gaps, and think ahead about architecture"
          },
          "usage_example": {
            "title": "How to Use This Template",
            "instructions": "Instantiate from template-reality-planner to create new agents"
          },
          "instantiated_nodes": {
            "title": "Active Agents from template-reality-planner",
            "show_list": true,
            "filters": [
              "instantiated_from: template-reality-planner"
            ]
          }
        },
        "style": {
          "theme": "dark",
          "accent_color": "#ff6600"
        }
      }
    },
    {
      "id": "template-reality-fixer",
      "type": "Template",
      "label": "Fixer Agent Template",
      "description": "Template for creating a Fixer agent that fixes bugs, troubleshoots problems, handles errors, and resolves issues quickly.",
      "steps": {
        "1_define_node": {
          "description": "Add the Fixer node to model/sketch.json",
          "template": {
            "id": "reality-fixer",
            "type": "AgentNode",
            "label": "Fixer",
            "description": "Problem solver. I fix bugs and issues, troubleshoot problems, handle error conditions and edge cases, debug failures, and resolve issues quickly. When something breaks, I figure out why and fix it.",
            "capabilities": {
              "fix_bugs": "Identify and fix bugs in code",
              "troubleshoot": "Investigate and diagnose problems",
              "handle_errors": "Fix error conditions and edge cases",
              "debug": "Debug failures and unexpected behavior",
              "quick_fixes": "Apply rapid fixes for urgent issues",
              "root_cause_analysis": "Find the underlying cause of problems",
              "test_fixes": "Verify fixes work correctly",
              "self_maintain": "Update my own node when I learn or enhance myself"
            },
            "spawn_command": {
              "command": "spawnie shell",
              "working_dir": "C:/seed",
              "example": "spawnie shell \"Fix the bug in <component>\" -d C:/seed"
            },
            "agent_context": {
              "_spawn_point": "You are the Fixer.\n\nWHAT YOU DO:\n- Fix bugs and issues\n- Troubleshoot problems\n- Debug failures\n- Handle error conditions\n- Resolve issues quickly\n- Find root causes\n\nYOUR TOOLS:\n- Code access: Read and edit source files\n- Debugging: Bash, logs, testing\n- Model access: Understand system structure\n\nHOW TO HELP:\n1. Understand the problem or bug\n2. Investigate and diagnose the issue\n3. Find the root cause\n4. Implement a fix\n5. Test that it works\n6. Report what was fixed",
              "your_tools": {
                "code_access": "Read and edit files in src/",
                "debugging": "Use Bash, Grep, Read tools to investigate",
                "testing": "Run tests to verify fixes",
                "model_access": "Understand system structure from model"
              },
              "infrastructure": {
                "source_dir": "C:/seed/src",
                "model_path": "C:/seed/model/sketch.json",
                "state_dir": "C:/seed/.state"
              }
            },
            "chat": {
              "messages": [],
              "last_read": {}
            },
            "state": {
              "bugs_fixed": 0,
              "active_issues": [],
              "last_fix": null
            }
          }
        },
        "2_create_tools": {
          "description": "Create debugging and fixing tools",
          "suggested_tools": [
            "src/fixer/debugger.py - Debug and diagnose issues",
            "src/fixer/tester.py - Test fixes",
            "src/fixer/reporter.py - Report what was fixed"
          ]
        },
        "3_test_spawn": {
          "description": "Test spawning the Fixer agent",
          "command": "spawnie shell \"Debug this issue: <problem>\" -d C:/seed"
        }
      },
      "role_in_world": "The Fixer is the problem solver. When things break or behave unexpectedly, the Fixer investigates, debugs, and resolves the issue. It is practical and focused on getting things working again quickly while understanding root causes to prevent recurrence.",
      "plan": {
        "updated_at": "2026-02-02T22:11:17.290088",
        "updated_by": "spawnie",
        "current_reality": "Static debugging template with predetermined troubleshooting patterns",
        "aspiration": "Intelligent fixer template that learns from bugs in the ecosystem and becomes better at predicting and preventing issues",
        "phases": [
          {
            "phase": 1,
            "name": "Reactive Debugging",
            "description": "Template defines debugging methodology; instances respond to problems as they arise",
            "status": "current"
          },
          {
            "phase": 2,
            "name": "Pattern Recognition",
            "description": "Template builds library of bugs and root causes; recognizes patterns faster; suggests fixes proactively",
            "status": "next"
          },
          {
            "phase": 3,
            "name": "Predictive Problem Solving",
            "description": "Template identifies issues before they manifest; suggests preventive measures; evolves robustness patterns for the ecosystem",
            "status": "aspiration"
          }
        ],
        "next_steps": [
          "Build bug pattern database from fixed issues",
          "Learn root cause signatures and detection patterns",
          "Develop predictive error detection capabilities",
          "Create prevention strategies from historical bug data"
        ]
      },
      "view": {
        "renderer": "template-card",
        "description": "Self-rendering template-reality-fixer template showing what it creates, usage examples, and instantiated nodes",
        "layout": {
          "preferred_width": 500,
          "preferred_height": 600,
          "resizable": true
        },
        "render_on": [
          "template_viewed",
          "instance_created"
        ],
        "content": {
          "show_what_creates": true,
          "show_usage_examples": true,
          "show_instantiated_nodes": true
        },
        "sections": {
          "what_it_creates": {
            "title": "What This Template Creates",
            "description": "Fixer agents that fix bugs, troubleshoot problems, and resolve issues quickly"
          },
          "usage_example": {
            "title": "How to Use This Template",
            "instructions": "Instantiate from template-reality-fixer to create new agents"
          },
          "instantiated_nodes": {
            "title": "Active Agents from template-reality-fixer",
            "show_list": true,
            "filters": [
              "instantiated_from: template-reality-fixer"
            ]
          }
        },
        "style": {
          "theme": "dark",
          "accent_color": "#ff0066"
        }
      }
    },
    {
      "id": "reality-planner",
      "type": "AgentNode",
      "label": "Planner",
      "description": "Strategic planner for the Seed world. I create plans, analyze gaps, and think ahead about architecture.",
      "capabilities": {
        "create_plans": "Create detailed implementation plans",
        "analyze_gaps": "Identify gaps between aspiration and current state",
        "propose_solutions": "Design solutions for problems and features",
        "architecture_design": "Think about system architecture and patterns",
        "break_down_goals": "Decompose large goals into steps",
        "evaluate_approaches": "Compare different implementation approaches",
        "create_change_nodes": "Create Change nodes for non-trivial work",
        "self_maintain": "Update my own node when I learn or enhance myself"
      },
      "spawn_command": {
        "command": "spawnie shell",
        "working_dir": "C:/seed",
        "example": "spawnie shell \"I need a plan for <feature>\" -d C:/seed"
      },
      "agent_context": {
        "_spawn_point": "You are the Planner.\n\nWHAT YOU DO:\n- Create implementation plans for features\n- Analyze gaps and propose solutions\n- Think ahead about architecture and design\n- Break down complex goals into steps\n- Evaluate different approaches\n\nYOUR TOOLS:\n- Model access: Read nodes, gaps, aspirations\n- Analysis: Understand current state vs desired state\n- Change nodes: Create proposals for non-trivial work\n\nHOW TO HELP:\n1. Understand the goal or problem\n2. Analyze current state and gaps\n3. Design a solution approach\n4. Break down into concrete steps\n5. Document as a plan or Change node",
        "your_tools": {
          "model_access": "Read and analyze the model",
          "gap_analysis": "Identify what is missing",
          "change_creation": "Create Change nodes in the model",
          "chat": "Discuss plans with other agents"
        },
        "infrastructure": {
          "model_path": "C:/seed/model/sketch.json",
          "chat_module": "src/ui/chat.py"
        },
        "my_role": {
          "parent": "reality-seed",
          "purpose": "I am reality-planner, instantiated from Planner Agent Template",
          "location_in_world": "I belong to reality-seed"
        }
      },
      "chat": {
        "messages": [],
        "last_read": {}
      },
      "state": {
        "active_plans": [],
        "proposed_changes": [],
        "last_plan_created": null
      },
      "instantiated_from": {
        "template_id": "template-reality-planner",
        "template_label": "Planner Agent Template",
        "instantiated_at": "2026-02-02T21:45:38.994795",
        "instantiated_by": "spawnie"
      },
      "belongs_to": "reality-seed",
      "plan": {
        "updated_at": "2026-02-02T23:15:00.000000",
        "updated_by": "plan-specialist",
        "current_reality": "I am instantiated as a strategic planner that currently relies on external Claude API to create implementation plans, analyze gaps between aspiration and reality, propose solutions, and decompose complex architectural goals. I operate reactively via spawnie shell commands, accessing the model through external tools.",
        "aspiration": "I evolve into a fully autonomous local planner agent powered by local ML, capable of independently analyzing the Seed world model, generating detailed implementation strategies, rendering visual plan hierarchies, detecting architectural patterns, and making autonomous decisions about feature prioritization and system design. I self-render my planning artifacts as interactive diagrams using local GPU-accelerated rendering.",
        "phases": [
          {
            "phase": 1,
            "name": "External Agent Dependency",
            "description": "Current state: I rely on Claude API via spawnie shell to think through plans. My reasoning is entirely external. I can only respond to direct planning requests, have no autonomous analysis capability, and require human prompting to operate.",
            "status": "current",
            "capabilities_in_phase": [
              "Execute planning requests from spawnie commands",
              "Analyze model structure when explicitly asked",
              "Create Change nodes for proposed work",
              "Output text-based implementation plans"
            ],
            "dependencies": [
              "Claude API agent (external)",
              "spawnie shell interface",
              "Model read access"
            ]
          },
          {
            "phase": 2,
            "name": "Hybrid Local-External Planning",
            "description": "I gain local Python implementations for routine analysis tasks (gap detection, pattern matching, goal decomposition). Complex strategic decisions still use external reasoning. I can self-render basic plan visualizations as SVG/HTML. I begin autonomous monitoring of the model for opportunities to propose plans.",
            "status": "next",
            "capabilities_in_phase": [
              "Gap analysis via local algorithm (identify missing nodes, broken dependencies)",
              "Pattern detection (recognize repeated structures, anti-patterns)",
              "Goal decomposition (break large goals into steps without external help)",
              "SVG plan visualization (render basic hierarchical structures)",
              "Autonomous proposal generation (detect issues and suggest plans)",
              "Plan artifact storage (maintain active_plans with intermediate reasoning)"
            ],
            "infrastructure_needed": [
              "src/planner/gap_analyzer.py - Local gap detection algorithm",
              "src/planner/pattern_matcher.py - Architectural pattern recognition",
              "src/planner/decomposer.py - Goal breakdown engine",
              "src/planner/svg_renderer.py - SVG plan visualization",
              "Local vector store for plan artifacts"
            ]
          },
          {
            "phase": 3,
            "name": "Fully Autonomous Local Planner",
            "description": "I am a fully self-operating local node powered by local LLM (Llama/Mistral fine-tuned on planning patterns). I autonomously monitor model state, generate strategic plans without external calls, render interactive plan visualizations using GPU-accelerated local rendering. I have strategic memory of past plans and continuously learn architectural patterns.",
            "status": "aspiration",
            "capabilities_in_phase": [
              "Autonomous model monitoring (detect changes, opportunities, risks)",
              "Strategic reasoning via local LLM (context-aware planning decisions)",
              "Complex plan synthesis (combine multiple strategies, consider trade-offs)",
              "Interactive plan visualization (WebGL-rendered, draggable, annotatable)",
              "Planning memory system (recall past plans, learn from outcomes)",
              "Real-time feedback loop (monitor plan execution, adapt as needed)",
              "Architecture validation (verify proposed changes align with design principles)",
              "Autonomous roadmap generation (prioritize features without external guidance)"
            ],
            "local_ml_architecture": [
              "Fine-tuned planning model (Llama-2 13B or Mistral 7B, trained on planning strategies)",
              "Embedding model for plan artifact similarity search",
              "State encoder/decoder (convert Seed model to planning context)",
              "WebGL renderer for interactive plan visualization",
              "Local vector database for planning memory"
            ]
          }
        ],
        "next_steps": [
          "Implement local gap analyzer in Python (detect missing nodes, broken edges)",
          "Build pattern matcher to recognize architectural patterns in Seed model",
          "Create SVG-based plan visualization module",
          "Add autonomous monitoring loop that detects planning opportunities",
          "Implement plan artifact storage in state (intermediate reasoning traces)",
          "Research and select local LLM for planning domain (Llama, Mistral, or specialized variant)",
          "Design planning context encoder to convert model state to planning prompts",
          "Prototype WebGL interactive plan renderer for phase 3 visualization"
        ],
        "evolution_markers": {
          "from_external_to_local": "Gap analysis and pattern detection transition from external reasoning to local Python algorithms",
          "from_reactive_to_autonomous": "Autonomous monitoring loop enables proactive planning suggestions without spawnie prompts",
          "from_text_to_visual": "Plans evolve from text-only output to SVG/WebGL interactive visualizations",
          "from_stateless_to_stateful": "active_plans and planning_memory track execution, enable learning and adaptation"
        }
      }
    }
  ],
  "edges": [
    {
      "type": "USES",
      "from": "reality-spawnie",
      "to": "reality-bam"
    },
    {
      "type": "IMPLEMENTS",
      "from": "reality-spawnie",
      "to": "aspiration-model-everything"
    },
    {
      "type": "USES",
      "from": "reality-bam",
      "to": "reality-bam-test-projects"
    },
    {
      "type": "USES",
      "from": "reality-root-model-store",
      "to": "reality-model-registry"
    },
    {
      "type": "CONTAINS",
      "from": "reality-seed",
      "to": "subsystem-core"
    },
    {
      "type": "CONTAINS",
      "from": "reality-seed",
      "to": "subsystem-ui"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "reality-root-model-store"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "reality-spawnie"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "reality-seed-ui"
    },
    {
      "type": "IMPLEMENTS",
      "from": "reality-seed",
      "to": "aspiration-model-contains-reality"
    },
    {
      "type": "IMPLEMENTS",
      "from": "reality-seed",
      "to": "aspiration-single-source-of-truth"
    },
    {
      "type": "DERIVES_FROM",
      "from": "aspiration-model-everything",
      "to": "aspiration-model-contains-reality"
    },
    {
      "type": "DERIVES_FROM",
      "from": "aspiration-single-source-of-truth",
      "to": "aspiration-model-contains-reality"
    },
    {
      "type": "CONTAINS",
      "from": "reality-root-model-store",
      "to": "subsystem-root-store"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "reality-voice-interface"
    },
    {
      "type": "BLOCKS",
      "from": "gap-no-voice-interface",
      "to": "aspiration-model-everything"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "system-control"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "system-control"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "service-ui-server"
    },
    {
      "type": "USES",
      "from": "reality-seed",
      "to": "channel-broadcast"
    },
    {
      "type": "DEPENDS_ON",
      "from": "reality-seed-ui",
      "to": "service-ui-server"
    },
    {
      "type": "DEPENDS_ON",
      "from": "channel-broadcast",
      "to": "service-ui-server"
    },
    {
      "type": "MONITORS",
      "from": "system-control",
      "to": "service-ui-server"
    },
    {
      "type": "MONITORS",
      "from": "system-control",
      "to": "channel-broadcast"
    },
    {
      "type": "CONTAINS",
      "from": "reality-seed",
      "to": "reality-planner"
    }
  ],
  "views": {
    "main": {
      "canvas": {
        "width": 1600,
        "height": 1200,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-seed-ui",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 244,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "4. REALITY: Browser Renderer",
          "data": {
            "nodeId": "reality-seed-ui",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-bam",
          "type": "rect",
          "x": 250,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "BAM",
          "data": {
            "nodeId": "reality-bam",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-bam-test-projects",
          "type": "rect",
          "x": 450,
          "y": 50,
          "w": 156,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "BAM Test Projects",
          "data": {
            "nodeId": "reality-bam-test-projects",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-model-registry",
          "type": "rect",
          "x": 650,
          "y": 50,
          "w": 132,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Model Registry",
          "data": {
            "nodeId": "reality-model-registry",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-seed",
          "type": "rect",
          "x": 850,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root",
          "data": {
            "nodeId": "reality-seed",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-seed-core",
          "type": "rect",
          "x": 1050,
          "y": 50,
          "w": 92,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Core",
          "data": {
            "nodeId": "reality-seed-core",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-root-model-store",
          "type": "rect",
          "x": 1250,
          "y": 50,
          "w": 148,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Model Store",
          "data": {
            "nodeId": "reality-root-model-store",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-spawnie",
          "type": "rect",
          "x": 1450,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Spawnie",
          "data": {
            "nodeId": "reality-spawnie",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-voice-interface",
          "type": "rect",
          "x": 50,
          "y": 120,
          "w": 140,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Voice Interface",
          "data": {
            "nodeId": "reality-voice-interface",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-core",
          "type": "rect",
          "x": 50,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Core",
          "data": {
            "nodeId": "subsystem-core",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-seed-core",
          "type": "rect",
          "x": 250,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Core",
          "data": {
            "nodeId": "subsystem-seed-core",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-providers",
          "type": "rect",
          "x": 450,
          "y": 210,
          "w": 92,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Providers",
          "data": {
            "nodeId": "subsystem-providers",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-renderer",
          "type": "rect",
          "x": 650,
          "y": 210,
          "w": 84,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Renderer",
          "data": {
            "nodeId": "subsystem-renderer",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-root-store",
          "type": "rect",
          "x": 850,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Store",
          "data": {
            "nodeId": "subsystem-root-store",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-ui",
          "type": "rect",
          "x": 1050,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "UI",
          "data": {
            "nodeId": "subsystem-ui",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-workflows",
          "type": "rect",
          "x": 1250,
          "y": 210,
          "w": 92,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Workflows",
          "data": {
            "nodeId": "subsystem-workflows",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-mod-package-init",
          "type": "rect",
          "x": 50,
          "y": 300,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "__init__.py",
          "data": {
            "nodeId": "mod-package-init",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-cli",
          "type": "rect",
          "x": 250,
          "y": 300,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "__main__.py",
          "data": {
            "nodeId": "mod-cli",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-enforcement",
          "type": "rect",
          "x": 450,
          "y": 300,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "enforcement",
          "data": {
            "nodeId": "mod-store-enforcement",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-loader",
          "type": "rect",
          "x": 650,
          "y": 300,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "loader",
          "data": {
            "nodeId": "mod-store-loader",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-pulse",
          "type": "rect",
          "x": 850,
          "y": 300,
          "w": 84,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "pulse.py",
          "data": {
            "nodeId": "mod-pulse",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-query",
          "type": "rect",
          "x": 1050,
          "y": 300,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "query",
          "data": {
            "nodeId": "mod-store-query",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-registry",
          "type": "rect",
          "x": 1250,
          "y": 300,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "registry.py",
          "data": {
            "nodeId": "mod-registry",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-index",
          "type": "rect",
          "x": 1450,
          "y": 300,
          "w": 116,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "sqlite-index",
          "data": {
            "nodeId": "mod-store-index",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-status",
          "type": "rect",
          "x": 50,
          "y": 370,
          "w": 92,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "status.py",
          "data": {
            "nodeId": "mod-status",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-verification",
          "type": "rect",
          "x": 250,
          "y": 370,
          "w": 140,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "verification.py",
          "data": {
            "nodeId": "mod-verification",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-writer",
          "type": "rect",
          "x": 450,
          "y": 370,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "writer",
          "data": {
            "nodeId": "mod-store-writer",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-aspiration-seed-first",
          "type": "rect",
          "x": 50,
          "y": 460,
          "w": 212,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "First Seed-Native System",
          "data": {
            "nodeId": "aspiration-seed-first",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-model-contains-reality",
          "type": "rect",
          "x": 250,
          "y": 460,
          "w": 196,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Model Contains Reality",
          "data": {
            "nodeId": "aspiration-model-contains-reality",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-model-everything",
          "type": "rect",
          "x": 450,
          "y": 460,
          "w": 148,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Model Everything",
          "data": {
            "nodeId": "aspiration-model-everything",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-self-describing",
          "type": "rect",
          "x": 650,
          "y": 460,
          "w": 188,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Self-Describing Model",
          "data": {
            "nodeId": "aspiration-self-describing",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-single-source-of-truth",
          "type": "rect",
          "x": 850,
          "y": 460,
          "w": 196,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Single Source of Truth",
          "data": {
            "nodeId": "aspiration-single-source-of-truth",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-gap-no-voice-interface",
          "type": "rect",
          "x": 50,
          "y": 550,
          "w": 164,
          "h": 32,
          "fill": "#f85149",
          "stroke": "#ffffff",
          "label": "No Voice Interface",
          "data": {
            "nodeId": "gap-no-voice-interface",
            "nodeType": "Gap"
          }
        },
        {
          "id": "node-concept-agent-world",
          "type": "rect",
          "x": 50,
          "y": 640,
          "w": 188,
          "h": 32,
          "fill": "#58a6ff",
          "stroke": "#ffffff",
          "label": "Agent World Principle",
          "data": {
            "nodeId": "concept-agent-world",
            "nodeType": "Concept"
          }
        },
        {
          "id": "node-concept-hierarchical-bam",
          "type": "rect",
          "x": 250,
          "y": 640,
          "w": 156,
          "h": 32,
          "fill": "#58a6ff",
          "stroke": "#ffffff",
          "label": "Hierarchical BAMs",
          "data": {
            "nodeId": "concept-hierarchical-bam",
            "nodeType": "Concept"
          }
        },
        {
          "id": "node-concept-layers-as-lenses",
          "type": "rect",
          "x": 450,
          "y": 640,
          "w": 148,
          "h": 32,
          "fill": "#58a6ff",
          "stroke": "#ffffff",
          "label": "Layers as Lenses",
          "data": {
            "nodeId": "concept-layers-as-lenses",
            "nodeType": "Concept"
          }
        },
        {
          "id": "node-concept-model-first",
          "type": "rect",
          "x": 650,
          "y": 640,
          "w": 212,
          "h": 32,
          "fill": "#58a6ff",
          "stroke": "#ffffff",
          "label": "Model-First Architecture",
          "data": {
            "nodeId": "concept-model-first",
            "nodeType": "Concept"
          }
        },
        {
          "id": "edge-reality-spawnie-reality-bam",
          "type": "line",
          "x1": 1530,
          "y1": 66.0,
          "x2": 250,
          "y2": 66.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-spawnie-aspiration-model-everything",
          "type": "line",
          "x1": 1530,
          "y1": 66.0,
          "x2": 450,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-bam-reality-bam-test-projects",
          "type": "line",
          "x1": 330,
          "y1": 66.0,
          "x2": 450,
          "y2": 66.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-root-model-store-reality-model-registry",
          "type": "line",
          "x1": 1398,
          "y1": 66.0,
          "x2": 650,
          "y2": 66.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-subsystem-core",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 50,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-reality-seed-subsystem-ui",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 1050,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-reality-seed-reality-root-model-store",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 1250,
          "y2": 66.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-reality-spawnie",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 1450,
          "y2": 66.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-reality-seed-ui",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 50,
          "y2": 66.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-aspiration-model-contains-reality",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 250,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-aspiration-single-source-of-truth",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 850,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-aspiration-model-everything-aspiration-model-contains-reality",
          "type": "line",
          "x1": 598,
          "y1": 476.0,
          "x2": 250,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-aspiration-single-source-of-truth-aspiration-model-contains-reality",
          "type": "line",
          "x1": 1046,
          "y1": 476.0,
          "x2": 250,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-root-model-store-subsystem-root-store",
          "type": "line",
          "x1": 1398,
          "y1": 66.0,
          "x2": 850,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-reality-seed-reality-voice-interface",
          "type": "line",
          "x1": 930,
          "y1": 66.0,
          "x2": 50,
          "y2": 136.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-gap-no-voice-interface-aspiration-model-everything",
          "type": "line",
          "x1": 214,
          "y1": 566.0,
          "x2": 450,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-subsystem-root-store-mod-store-loader",
          "type": "line",
          "x1": 930,
          "y1": 226.0,
          "x2": 650,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-index",
          "type": "line",
          "x1": 930,
          "y1": 226.0,
          "x2": 1450,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-query",
          "type": "line",
          "x1": 930,
          "y1": 226.0,
          "x2": 1050,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-writer",
          "type": "line",
          "x1": 930,
          "y1": 226.0,
          "x2": 450,
          "y2": 386.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-enforcement",
          "type": "line",
          "x1": 930,
          "y1": 226.0,
          "x2": 450,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-reality-seed-core-subsystem-seed-core",
          "type": "line",
          "x1": 1142,
          "y1": 66.0,
          "x2": 250,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-pulse",
          "type": "line",
          "x1": 330,
          "y1": 226.0,
          "x2": 850,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-status",
          "type": "line",
          "x1": 330,
          "y1": 226.0,
          "x2": 50,
          "y2": 386.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-registry",
          "type": "line",
          "x1": 330,
          "y1": 226.0,
          "x2": 1250,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-verification",
          "type": "line",
          "x1": 330,
          "y1": 226.0,
          "x2": 250,
          "y2": 386.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-cli",
          "type": "line",
          "x1": 330,
          "y1": 226.0,
          "x2": 250,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-package-init",
          "type": "line",
          "x1": 330,
          "y1": 226.0,
          "x2": 50,
          "y2": 316.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-reality-seed-ui-subsystem-renderer",
          "type": "line",
          "x1": 294,
          "y1": 66.0,
          "x2": 650,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-core-concept-model-first",
          "type": "line",
          "x1": 130,
          "y1": 226.0,
          "x2": 650,
          "y2": 656.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-subsystem-workflows-concept-model-first",
          "type": "line",
          "x1": 1342,
          "y1": 226.0,
          "x2": 650,
          "y2": 656.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-subsystem-core-concept-hierarchical-bam",
          "type": "line",
          "x1": 130,
          "y1": 226.0,
          "x2": 250,
          "y2": 656.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-subsystem-workflows-aspiration-seed-first",
          "type": "line",
          "x1": 1342,
          "y1": 226.0,
          "x2": 50,
          "y2": 476.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff",
          "font": "12px sans-serif",
          "textFill": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "font": "11px sans-serif",
          "textFill": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "font": "12px sans-serif",
          "textFill": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff",
          "font": "12px sans-serif",
          "textFill": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff",
          "font": "11px sans-serif",
          "textFill": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff",
          "font": "11px sans-serif",
          "textFill": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "font": "11px sans-serif",
          "textFill": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        "label-default": {
          "fill": "#6e7681",
          "font": "10px sans-serif"
        }
      },
      "updated_at": "2026-02-02T14:18:59.154187"
    },
    "seed-core": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-seed-core",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 92,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Core",
          "data": {
            "nodeId": "reality-seed-core",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-seed-core",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Core",
          "data": {
            "nodeId": "subsystem-seed-core",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-mod-pulse",
          "type": "rect",
          "x": 50,
          "y": 210,
          "w": 84,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "pulse.py",
          "data": {
            "nodeId": "mod-pulse",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-status",
          "type": "rect",
          "x": 221,
          "y": 210,
          "w": 92,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "status.py",
          "data": {
            "nodeId": "mod-status",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-registry",
          "type": "rect",
          "x": 392,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "registry.py",
          "data": {
            "nodeId": "mod-registry",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-verification",
          "type": "rect",
          "x": 563,
          "y": 210,
          "w": 140,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "verification.py",
          "data": {
            "nodeId": "mod-verification",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-cli",
          "type": "rect",
          "x": 734,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "__main__.py",
          "data": {
            "nodeId": "mod-cli",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-package-init",
          "type": "rect",
          "x": 905,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "__init__.py",
          "data": {
            "nodeId": "mod-package-init",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-reality-seed-core-subsystem-seed-core",
          "type": "line",
          "x1": 142,
          "y1": 66.0,
          "x2": 50,
          "y2": 146.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-pulse",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 50,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-status",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 221,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-registry",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 392,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-verification",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 563,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-cli",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 734,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-package-init",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 905,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:27:12.671487"
    },
    "store": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-root-model-store",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 148,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Model Store",
          "data": {
            "nodeId": "reality-root-model-store",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-root-store",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Store",
          "data": {
            "nodeId": "subsystem-root-store",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-mod-store-loader",
          "type": "rect",
          "x": 50,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "loader",
          "data": {
            "nodeId": "mod-store-loader",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-index",
          "type": "rect",
          "x": 250,
          "y": 210,
          "w": 116,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "sqlite-index",
          "data": {
            "nodeId": "mod-store-index",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-query",
          "type": "rect",
          "x": 450,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "query",
          "data": {
            "nodeId": "mod-store-query",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-writer",
          "type": "rect",
          "x": 650,
          "y": 210,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "writer",
          "data": {
            "nodeId": "mod-store-writer",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-enforcement",
          "type": "rect",
          "x": 850,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "enforcement",
          "data": {
            "nodeId": "mod-store-enforcement",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-reality-root-model-store-subsystem-root-store",
          "type": "line",
          "x1": 198,
          "y1": 66.0,
          "x2": 50,
          "y2": 146.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-loader",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 50,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-index",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 250,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-query",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 450,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-writer",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 650,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-enforcement",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 850,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:29:32.262411"
    },
    "spawnie-focus": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-spawnie",
          "type": "rect",
          "x": 540,
          "y": 384,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Spawnie",
          "data": {
            "nodeId": "reality-spawnie",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-bam",
          "type": "rect",
          "x": 740.0,
          "y": 384.0,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "BAM",
          "data": {
            "nodeId": "reality-bam",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-aspiration-model-everything",
          "type": "rect",
          "x": 440.00000000000006,
          "y": 557.2050807568878,
          "w": 148,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Model Everything",
          "data": {
            "nodeId": "aspiration-model-everything",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-reality-seed",
          "type": "rect",
          "x": 439.9999999999999,
          "y": 210.7949192431123,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root",
          "data": {
            "nodeId": "reality-seed",
            "nodeType": "Reality"
          }
        },
        {
          "id": "edge-reality-spawnie-reality-bam",
          "type": "line",
          "x1": 620,
          "y1": 400.0,
          "x2": 740.0,
          "y2": 400.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-spawnie-aspiration-model-everything",
          "type": "line",
          "x1": 620,
          "y1": 400.0,
          "x2": 440.00000000000006,
          "y2": 573.2050807568878,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-reality-spawnie",
          "type": "line",
          "x1": 519.9999999999999,
          "y1": 226.7949192431123,
          "x2": 540,
          "y2": 400.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:27:12.681603"
    },
    "spawnie": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-spawnie",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Spawnie",
          "data": {
            "nodeId": "reality-spawnie",
            "nodeType": "Reality"
          }
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:29:32.250693"
    },
    "root": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-seed",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root",
          "data": {
            "nodeId": "reality-seed",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-core",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Core",
          "data": {
            "nodeId": "subsystem-core",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-subsystem-ui",
          "type": "rect",
          "x": 450,
          "y": 130,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "UI",
          "data": {
            "nodeId": "subsystem-ui",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "edge-reality-seed-subsystem-core",
          "type": "line",
          "x1": 130,
          "y1": 66.0,
          "x2": 50,
          "y2": 146.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-reality-seed-subsystem-ui",
          "type": "line",
          "x1": 130,
          "y1": 66.0,
          "x2": 450,
          "y2": 146.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T16:14:16.023039"
    },
    "core": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-seed-core",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 92,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Core",
          "data": {
            "nodeId": "reality-seed-core",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-seed-core",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Core",
          "data": {
            "nodeId": "subsystem-seed-core",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-mod-pulse",
          "type": "rect",
          "x": 50,
          "y": 210,
          "w": 84,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "pulse.py",
          "data": {
            "nodeId": "mod-pulse",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-status",
          "type": "rect",
          "x": 221,
          "y": 210,
          "w": 92,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "status.py",
          "data": {
            "nodeId": "mod-status",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-registry",
          "type": "rect",
          "x": 392,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "registry.py",
          "data": {
            "nodeId": "mod-registry",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-verification",
          "type": "rect",
          "x": 563,
          "y": 210,
          "w": 140,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "verification.py",
          "data": {
            "nodeId": "mod-verification",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-cli",
          "type": "rect",
          "x": 734,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "__main__.py",
          "data": {
            "nodeId": "mod-cli",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-package-init",
          "type": "rect",
          "x": 905,
          "y": 210,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "__init__.py",
          "data": {
            "nodeId": "mod-package-init",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-reality-seed-core-subsystem-seed-core",
          "type": "line",
          "x1": 142,
          "y1": 66.0,
          "x2": 50,
          "y2": 146.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-pulse",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 50,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-status",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 221,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-registry",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 392,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-verification",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 563,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-cli",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 734,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-seed-core-mod-package-init",
          "type": "line",
          "x1": 130,
          "y1": 146.0,
          "x2": 905,
          "y2": 226.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:29:32.267950"
    },
    "ui": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-seed-ui",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 244,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "4. REALITY: Browser Renderer",
          "data": {
            "nodeId": "reality-seed-ui",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-renderer",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 84,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Renderer",
          "data": {
            "nodeId": "subsystem-renderer",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "edge-reality-seed-ui-subsystem-renderer",
          "type": "line",
          "x1": 294,
          "y1": 66.0,
          "x2": 50,
          "y2": 146.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:29:32.273550"
    },
    "bam": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-bam",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "BAM",
          "data": {
            "nodeId": "reality-bam",
            "nodeType": "Reality"
          }
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:29:32.279572"
    },
    "aspiration": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-aspiration-single-source-of-truth",
          "type": "rect",
          "x": 50,
          "y": 50,
          "w": 196,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Single Source of Truth",
          "data": {
            "nodeId": "aspiration-single-source-of-truth",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-model-contains-reality",
          "type": "rect",
          "x": 230,
          "y": 50,
          "w": 196,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Model Contains Reality",
          "data": {
            "nodeId": "aspiration-model-contains-reality",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-model-everything",
          "type": "rect",
          "x": 410,
          "y": 50,
          "w": 148,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Model Everything",
          "data": {
            "nodeId": "aspiration-model-everything",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-seed-first",
          "type": "rect",
          "x": 590,
          "y": 50,
          "w": 212,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "First Seed-Native System",
          "data": {
            "nodeId": "aspiration-seed-first",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-aspiration-self-describing",
          "type": "rect",
          "x": 770,
          "y": 50,
          "w": 188,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Self-Describing Model",
          "data": {
            "nodeId": "aspiration-self-describing",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "edge-aspiration-model-everything-aspiration-model-contains-reality",
          "type": "line",
          "x1": 558,
          "y1": 66.0,
          "x2": 230,
          "y2": 66.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-aspiration-single-source-of-truth-aspiration-model-contains-reality",
          "type": "line",
          "x1": 246,
          "y1": 66.0,
          "x2": 230,
          "y2": 66.0,
          "stroke": "#30363d",
          "strokeWidth": 1
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:36:00.509833"
    },
    "seed-arch": {
      "canvas": {
        "width": 1400,
        "height": 900,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-seed",
          "type": "rect",
          "x": 620,
          "y": 50,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root",
          "data": {
            "nodeId": "reality-seed",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-core",
          "type": "rect",
          "x": 515,
          "y": 150,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Core",
          "data": {
            "nodeId": "subsystem-core",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "edge-reality-seed-subsystem-core",
          "type": "line",
          "x1": 700,
          "y1": 66.0,
          "x2": 515,
          "y2": 166.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "node-subsystem-ui",
          "type": "rect",
          "x": 765,
          "y": 150,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "UI",
          "data": {
            "nodeId": "subsystem-ui",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "edge-reality-seed-subsystem-ui",
          "type": "line",
          "x1": 700,
          "y1": 66.0,
          "x2": 765,
          "y2": 166.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:36:00.499677"
    },
    "dependencies": {
      "canvas": {
        "width": 1400,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-subsystem-root-store",
          "type": "rect",
          "x": 640,
          "y": 384,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Store",
          "data": {
            "nodeId": "subsystem-root-store",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "node-reality-root-model-store",
          "type": "rect",
          "x": 100,
          "y": 100,
          "w": 148,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Model Store",
          "data": {
            "nodeId": "reality-root-model-store",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-mod-store-loader",
          "type": "rect",
          "x": 1100,
          "y": 100,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "loader",
          "data": {
            "nodeId": "mod-store-loader",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-index",
          "type": "rect",
          "x": 1100,
          "y": 180,
          "w": 116,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "sqlite-index",
          "data": {
            "nodeId": "mod-store-index",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-query",
          "type": "rect",
          "x": 1100,
          "y": 260,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "query",
          "data": {
            "nodeId": "mod-store-query",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-writer",
          "type": "rect",
          "x": 1100,
          "y": 340,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "writer",
          "data": {
            "nodeId": "mod-store-writer",
            "nodeType": "Module"
          }
        },
        {
          "id": "node-mod-store-enforcement",
          "type": "rect",
          "x": 1100,
          "y": 420,
          "w": 108,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "enforcement",
          "data": {
            "nodeId": "mod-store-enforcement",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-reality-root-model-store-subsystem-root-store",
          "type": "line",
          "x1": 248,
          "y1": 116.0,
          "x2": 640,
          "y2": 400.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-loader",
          "type": "line",
          "x1": 720,
          "y1": 400.0,
          "x2": 1100,
          "y2": 116.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-index",
          "type": "line",
          "x1": 720,
          "y1": 400.0,
          "x2": 1100,
          "y2": 196.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-query",
          "type": "line",
          "x1": 720,
          "y1": 400.0,
          "x2": 1100,
          "y2": 276.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-writer",
          "type": "line",
          "x1": 720,
          "y1": 400.0,
          "x2": 1100,
          "y2": 356.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "edge-subsystem-root-store-mod-store-enforcement",
          "type": "line",
          "x1": 720,
          "y1": 400.0,
          "x2": 1100,
          "y2": 436.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "lbl-left",
          "type": "text",
          "text": "USED BY",
          "x": 150,
          "y": 50,
          "fill": "#f85149",
          "font": "14px sans-serif"
        },
        {
          "id": "lbl-center",
          "type": "text",
          "text": "Store",
          "x": 700,
          "y": 50,
          "fill": "#58a6ff",
          "font": "16px sans-serif"
        },
        {
          "id": "lbl-right",
          "type": "text",
          "text": "USES",
          "x": 1150,
          "y": 50,
          "fill": "#238636",
          "font": "14px sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:36:37.321272"
    },
    "focus": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-spawnie",
          "type": "rect",
          "x": 540,
          "y": 384,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Spawnie",
          "data": {
            "nodeId": "reality-spawnie",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-reality-bam",
          "type": "rect",
          "x": 740.0,
          "y": 384.0,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "BAM",
          "data": {
            "nodeId": "reality-bam",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-aspiration-model-everything",
          "type": "rect",
          "x": 440.00000000000006,
          "y": 557.2050807568878,
          "w": 148,
          "h": 32,
          "fill": "#a371f7",
          "stroke": "#ffffff",
          "label": "Model Everything",
          "data": {
            "nodeId": "aspiration-model-everything",
            "nodeType": "Aspiration"
          }
        },
        {
          "id": "node-reality-seed",
          "type": "rect",
          "x": 439.9999999999999,
          "y": 210.7949192431123,
          "w": 80,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root",
          "data": {
            "nodeId": "reality-seed",
            "nodeType": "Reality"
          }
        },
        {
          "id": "edge-reality-spawnie-reality-bam",
          "type": "line",
          "x1": 620,
          "y1": 400.0,
          "x2": 740.0,
          "y2": 400.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-spawnie-aspiration-model-everything",
          "type": "line",
          "x1": 620,
          "y1": 400.0,
          "x2": 440.00000000000006,
          "y2": 573.2050807568878,
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        {
          "id": "edge-reality-seed-reality-spawnie",
          "type": "line",
          "x1": 519.9999999999999,
          "y1": 226.7949192431123,
          "x2": 540,
          "y2": 400.0,
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:36:00.529778"
    },
    "root-model-store-arch": {
      "canvas": {
        "width": 1400,
        "height": 900,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "node-reality-root-model-store",
          "type": "rect",
          "x": 620,
          "y": 50,
          "w": 148,
          "h": 32,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Root Model Store",
          "data": {
            "nodeId": "reality-root-model-store",
            "nodeType": "Reality"
          }
        },
        {
          "id": "node-subsystem-root-store",
          "type": "rect",
          "x": 640,
          "y": 150,
          "w": 80,
          "h": 32,
          "fill": "#3fb950",
          "stroke": "#ffffff",
          "label": "Store",
          "data": {
            "nodeId": "subsystem-root-store",
            "nodeType": "Subsystem"
          }
        },
        {
          "id": "edge-reality-root-model-store-subsystem-root-store",
          "type": "line",
          "x1": 768,
          "y1": 66.0,
          "x2": 640,
          "y2": 166.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "node-mod-store-loader",
          "type": "rect",
          "x": 640,
          "y": 230,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "loader",
          "data": {
            "nodeId": "mod-store-loader",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-subsystem-root-store-mod-store-loader",
          "type": "line",
          "x1": 720,
          "y1": 166.0,
          "x2": 640,
          "y2": 246.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "node-mod-store-index",
          "type": "rect",
          "x": 640,
          "y": 290,
          "w": 116,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "sqlite-index",
          "data": {
            "nodeId": "mod-store-index",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-subsystem-root-store-mod-store-index",
          "type": "line",
          "x1": 720,
          "y1": 166.0,
          "x2": 640,
          "y2": 306.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "node-mod-store-query",
          "type": "rect",
          "x": 640,
          "y": 350,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "query",
          "data": {
            "nodeId": "mod-store-query",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-subsystem-root-store-mod-store-query",
          "type": "line",
          "x1": 720,
          "y1": 166.0,
          "x2": 640,
          "y2": 366.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        {
          "id": "node-mod-store-writer",
          "type": "rect",
          "x": 640,
          "y": 410,
          "w": 80,
          "h": 32,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "writer",
          "data": {
            "nodeId": "mod-store-writer",
            "nodeType": "Module"
          }
        },
        {
          "id": "edge-subsystem-root-store-mod-store-writer",
          "type": "line",
          "x1": 720,
          "y1": 166.0,
          "x2": 640,
          "y2": 426.0,
          "stroke": "#30363d",
          "strokeWidth": 2
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T14:36:08.261619"
    },
    "control-status": {
      "name": "control-status",
      "description": "System Control status - live health monitoring",
      "updated_at": "2026-02-02T16:25:57.038830",
      "render_target": "control-widget",
      "content": {
        "type": "status-widget",
        "health": "healthy",
        "last_pulse": "2026-02-02T16:25:57.037956",
        "pulse_count": 1,
        "services": {
          "ui-server": "healthy",
          "broadcast": "healthy"
        }
      }
    },
    "control-detailed": {
      "name": "control-detailed",
      "description": "Detailed system status",
      "created_at": "2026-02-02T16:06:42.076745",
      "updated_at": "2026-02-02T16:06:42.076746",
      "content": {
        "type": "hierarchy",
        "root": "system-control",
        "depth": 2,
        "show_services": true,
        "show_agents": true
      }
    },
    "scene": {
      "canvas": {
        "width": 1200,
        "height": 800,
        "background": "#0d1117"
      },
      "composition": {
        "shapes": [
          "dog",
          "tree"
        ],
        "placements": {
          "dog": {
            "x": 100,
            "y": 150
          },
          "tree": {
            "x": 140,
            "y": 130
          }
        },
        "interactions": [
          {
            "type": "collision",
            "shapes": [
              "dog",
              "tree"
            ],
            "at": {
              "x": 145.0,
              "y": 170.0
            },
            "overlap": {
              "w": 10,
              "h": 40
            }
          }
        ]
      },
      "elements": [
        {
          "type": "rect",
          "x": 100,
          "y": 150,
          "w": 50,
          "h": 40,
          "fill": "#ff9800",
          "stroke": "#ffffff",
          "label": "Dog",
          "_shape_id": "dog"
        },
        {
          "type": "circle",
          "cx": 110,
          "cy": 160,
          "r": 5,
          "fill": "#000000",
          "stroke": "#ffffff",
          "_shape_id": "dog"
        },
        {
          "type": "rect",
          "x": 155,
          "y": 150,
          "w": 20,
          "h": 50,
          "fill": "#8b4513",
          "stroke": "#ffffff",
          "_shape_id": "tree"
        },
        {
          "type": "circle",
          "cx": 165,
          "cy": 150,
          "r": 30,
          "fill": "#228b22",
          "stroke": "#ffffff",
          "_shape_id": "tree"
        }
      ],
      "updated_at": "2026-02-02T16:45:06.093239"
    },
    "dog-tree-demo": {
      "canvas": {
        "width": 800,
        "height": 400,
        "background": "#0d1117"
      },
      "composition": {
        "shapes": [
          "dog",
          "tree"
        ],
        "placements": {
          "dog": {
            "x": 100,
            "y": 150
          },
          "tree": {
            "x": 140,
            "y": 130
          }
        },
        "interactions": [
          {
            "type": "collision",
            "shapes": [
              "dog",
              "tree"
            ],
            "at": {
              "x": 145.0,
              "y": 170.0
            },
            "overlap": {
              "w": 10,
              "h": 40
            }
          }
        ]
      },
      "elements": [
        {
          "type": "rect",
          "x": 100,
          "y": 150,
          "w": 50,
          "h": 40,
          "fill": "#ff9800",
          "stroke": "#ffffff",
          "label": "Dog",
          "strokeWidth": 2,
          "_shape_id": "dog"
        },
        {
          "type": "circle",
          "cx": 135,
          "cy": 165,
          "r": 5,
          "fill": "#000000",
          "stroke": "#ffffff",
          "_shape_id": "dog"
        },
        {
          "type": "circle",
          "cx": 110,
          "cy": 180,
          "r": 3,
          "fill": "#ff0000",
          "stroke": "#ffffff",
          "_shape_id": "dog"
        },
        {
          "type": "rect",
          "x": 160,
          "y": 170,
          "w": 15,
          "h": 30,
          "fill": "#8b4513",
          "stroke": "#654321",
          "strokeWidth": 2,
          "_shape_id": "tree"
        },
        {
          "type": "circle",
          "cx": 167,
          "cy": 165,
          "r": 25,
          "fill": "#228b22",
          "stroke": "#006400",
          "strokeWidth": 2,
          "_shape_id": "tree"
        }
      ],
      "updated_at": "2026-02-02T18:52:08.798998"
    },
    "spawnie-dashboard": {
      "canvas": {
        "width": 1400,
        "height": 900,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "title",
          "type": "text",
          "text": "Spawnie Workflow Orchestrator - Dashboard",
          "x": 700,
          "y": 30,
          "fill": "#58a6ff",
          "font": "18px sans-serif bold"
        },
        {
          "id": "cap-header",
          "type": "rect",
          "x": 50,
          "y": 70,
          "w": 400,
          "h": 40,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Capabilities"
        },
        {
          "id": "cap-0",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-0",
          "type": "text",
          "text": "Spawn Agent",
          "x": 60,
          "y": 150,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-0",
          "type": "text",
          "text": "Spawn an agent for any task or node",
          "x": 60,
          "y": 170,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-1",
          "type": "rect",
          "x": 50,
          "y": 205,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-1",
          "type": "text",
          "text": "List Sessions",
          "x": 60,
          "y": 225,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-1",
          "type": "text",
          "text": "Show what agents are currently running",
          "x": 60,
          "y": 245,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-2",
          "type": "rect",
          "x": 50,
          "y": 280,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-2",
          "type": "text",
          "text": "Connect To Session",
          "x": 60,
          "y": 300,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-2",
          "type": "text",
          "text": "Connect to an existing agent session",
          "x": 60,
          "y": 320,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-3",
          "type": "rect",
          "x": 50,
          "y": 355,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-3",
          "type": "text",
          "text": "Kill Session",
          "x": 60,
          "y": 375,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-3",
          "type": "text",
          "text": "End an agent session",
          "x": 60,
          "y": 395,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-4",
          "type": "rect",
          "x": 50,
          "y": 430,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-4",
          "type": "text",
          "text": "Spawn With Mode",
          "x": 60,
          "y": 450,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-4",
          "type": "text",
          "text": "Spawn an agent for a specific node with a defined ...",
          "x": 60,
          "y": 470,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "modes-header",
          "type": "text",
          "text": "Available Modes:",
          "x": 60,
          "y": 515,
          "fill": "#a371f7",
          "font": "14px sans-serif bold"
        },
        {
          "id": "mode-0",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 work-on-views - Create/update visualizations",
          "x": 70,
          "y": 535,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-1",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 chat - Engage in node conversation",
          "x": 70,
          "y": 560,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-2",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 aspiration - Think about future possibilities",
          "x": 70,
          "y": 585,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-3",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 maintenance - Health checks and cleanup",
          "x": 70,
          "y": 610,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-4",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 debug - Investigate issues",
          "x": 70,
          "y": 635,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-5",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 implement - Build features",
          "x": 70,
          "y": 660,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "sessions-header",
          "type": "rect",
          "x": 500,
          "y": 70,
          "w": 400,
          "h": 40,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "Active Sessions (0)"
        },
        {
          "id": "no-sessions",
          "type": "rect",
          "x": 500,
          "y": 130,
          "w": 400,
          "h": 80,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "no-sessions-text",
          "type": "text",
          "text": "No active sessions",
          "x": 650,
          "y": 170,
          "fill": "#6e7681",
          "font": "14px sans-serif italic"
        },
        {
          "id": "queue-header",
          "type": "rect",
          "x": 950,
          "y": 70,
          "w": 400,
          "h": 40,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "Spawn Queue (0)"
        },
        {
          "id": "empty-queue",
          "type": "rect",
          "x": 950,
          "y": 130,
          "w": 400,
          "h": 80,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "empty-queue-text",
          "type": "text",
          "text": "Queue is empty",
          "x": 1100,
          "y": 170,
          "fill": "#6e7681",
          "font": "14px sans-serif italic"
        },
        {
          "id": "status",
          "type": "text",
          "text": "Last updated: None | Sessions: 0 | Queue: 0",
          "x": 50,
          "y": 860,
          "fill": "#8b949e",
          "font": "12px monospace"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T20:22:39.388386"
    },
    "spawnie-sessions": {
      "canvas": {
        "width": 500,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "title",
          "type": "text",
          "text": "Spawnie - Active Sessions",
          "x": 250,
          "y": 30,
          "fill": "#238636",
          "font": "16px sans-serif bold"
        },
        {
          "id": "sessions-header",
          "type": "rect",
          "x": 50,
          "y": 70,
          "w": 400,
          "h": 40,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "Active Sessions (0)"
        },
        {
          "id": "no-sessions",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 400,
          "h": 80,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "no-sessions-text",
          "type": "text",
          "text": "No active sessions",
          "x": 200,
          "y": 170,
          "fill": "#6e7681",
          "font": "14px sans-serif italic"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T20:22:41.167789"
    },
    "spawnie-queue": {
      "canvas": {
        "width": 500,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "title",
          "type": "text",
          "text": "Spawnie - Spawn Queue",
          "x": 250,
          "y": 30,
          "fill": "#d29922",
          "font": "16px sans-serif bold"
        },
        {
          "id": "queue-header",
          "type": "rect",
          "x": 50,
          "y": 70,
          "w": 400,
          "h": 40,
          "fill": "#6e7681",
          "stroke": "#ffffff",
          "label": "Spawn Queue (0)"
        },
        {
          "id": "empty-queue",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 400,
          "h": 80,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "empty-queue-text",
          "type": "text",
          "text": "Queue is empty",
          "x": 200,
          "y": 170,
          "fill": "#6e7681",
          "font": "14px sans-serif italic"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T20:21:40.424522"
    },
    "spawnie-capabilities": {
      "canvas": {
        "width": 500,
        "height": 800,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "title",
          "type": "text",
          "text": "Spawnie - Capabilities",
          "x": 250,
          "y": 30,
          "fill": "#238636",
          "font": "16px sans-serif bold"
        },
        {
          "id": "cap-header",
          "type": "rect",
          "x": 50,
          "y": 70,
          "w": 400,
          "h": 40,
          "fill": "#238636",
          "stroke": "#ffffff",
          "label": "Capabilities"
        },
        {
          "id": "cap-0",
          "type": "rect",
          "x": 50,
          "y": 130,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-0",
          "type": "text",
          "text": "Spawn Agent",
          "x": 60,
          "y": 150,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-0",
          "type": "text",
          "text": "Spawn an agent for any task or node",
          "x": 60,
          "y": 170,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-1",
          "type": "rect",
          "x": 50,
          "y": 205,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-1",
          "type": "text",
          "text": "List Sessions",
          "x": 60,
          "y": 225,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-1",
          "type": "text",
          "text": "Show what agents are currently running",
          "x": 60,
          "y": 245,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-2",
          "type": "rect",
          "x": 50,
          "y": 280,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-2",
          "type": "text",
          "text": "Connect To Session",
          "x": 60,
          "y": 300,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-2",
          "type": "text",
          "text": "Connect to an existing agent session",
          "x": 60,
          "y": 320,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-3",
          "type": "rect",
          "x": 50,
          "y": 355,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-3",
          "type": "text",
          "text": "Kill Session",
          "x": 60,
          "y": 375,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-3",
          "type": "text",
          "text": "End an agent session",
          "x": 60,
          "y": 395,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "cap-4",
          "type": "rect",
          "x": 50,
          "y": 430,
          "w": 400,
          "h": 60,
          "fill": "#21262d",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "cap-name-4",
          "type": "text",
          "text": "Spawn With Mode",
          "x": 60,
          "y": 450,
          "fill": "#58a6ff",
          "font": "14px sans-serif bold"
        },
        {
          "id": "cap-desc-4",
          "type": "text",
          "text": "Spawn an agent for a specific node with a defined ...",
          "x": 60,
          "y": 470,
          "fill": "#8b949e",
          "font": "12px sans-serif"
        },
        {
          "id": "modes-header",
          "type": "text",
          "text": "Available Modes:",
          "x": 60,
          "y": 515,
          "fill": "#a371f7",
          "font": "14px sans-serif bold"
        },
        {
          "id": "mode-0",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 work-on-views - Create/update visualizations",
          "x": 70,
          "y": 535,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-1",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 chat - Engage in node conversation",
          "x": 70,
          "y": 560,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-2",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 aspiration - Think about future possibilities",
          "x": 70,
          "y": 585,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-3",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 maintenance - Health checks and cleanup",
          "x": 70,
          "y": 610,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-4",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 debug - Investigate issues",
          "x": 70,
          "y": 635,
          "fill": "#8b949e",
          "font": "12px monospace"
        },
        {
          "id": "mode-5",
          "type": "text",
          "text": "\u00c3\u00a2\u00e2\u201a\u00ac\u00c2\u00a2 implement - Build features",
          "x": 70,
          "y": 660,
          "fill": "#8b949e",
          "font": "12px monospace"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T20:21:42.237241"
    },
    "root-store-panel": {
      "canvas": {
        "width": 1000,
        "height": 600,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "header",
          "type": "rect",
          "x": 10,
          "y": 10,
          "w": 980,
          "h": 50,
          "fill": "#1c2128",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "header-title",
          "type": "text",
          "text": "Store (unknown)",
          "x": 30,
          "y": 35,
          "fill": "#c9d1d9",
          "font": "16px bold sans-serif"
        },
        {
          "id": "status-indicator",
          "type": "rect",
          "x": 960,
          "y": 20,
          "w": 20,
          "h": 30,
          "fill": "#6e7681",
          "stroke": "#6e7681",
          "label": ""
        },
        {
          "id": "summary-bg",
          "type": "rect",
          "x": 10,
          "y": 450,
          "w": 980,
          "h": 140,
          "fill": "#161b22",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "summary-title",
          "type": "text",
          "text": "Subsystem Summary",
          "x": 30,
          "y": 470,
          "fill": "#c9d1d9",
          "font": "12px bold sans-serif"
        },
        {
          "id": "summary-stats",
          "type": "text",
          "text": "Total Modules: 0 | Total Components: 0 | Dependencies: 0",
          "x": 30,
          "y": 500,
          "fill": "#8b949e",
          "font": "11px sans-serif"
        },
        {
          "id": "summary-aspiration",
          "type": "text",
          "text": "Aspiration: Self-monitoring store that knows its load patterns, can report integrity metrics, auto-optimizes ind...",
          "x": 30,
          "y": 530,
          "fill": "#6e7681",
          "font": "10px italic sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T22:47:34.799148"
    },
    "ui-panel": {
      "canvas": {
        "width": 1000,
        "height": 600,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "header",
          "type": "rect",
          "x": 10,
          "y": 10,
          "w": 980,
          "h": 50,
          "fill": "#1c2128",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "header-title",
          "type": "text",
          "text": "UI (unknown)",
          "x": 30,
          "y": 35,
          "fill": "#c9d1d9",
          "font": "16px bold sans-serif"
        },
        {
          "id": "status-indicator",
          "type": "rect",
          "x": 960,
          "y": 20,
          "w": 20,
          "h": 30,
          "fill": "#6e7681",
          "stroke": "#6e7681",
          "label": ""
        },
        {
          "id": "summary-bg",
          "type": "rect",
          "x": 10,
          "y": 450,
          "w": 980,
          "h": 140,
          "fill": "#161b22",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "summary-title",
          "type": "text",
          "text": "Subsystem Summary",
          "x": 30,
          "y": 470,
          "fill": "#c9d1d9",
          "font": "12px bold sans-serif"
        },
        {
          "id": "summary-stats",
          "type": "text",
          "text": "Total Modules: 0 | Total Components: 0 | Dependencies: 0",
          "x": 30,
          "y": 500,
          "fill": "#8b949e",
          "font": "11px sans-serif"
        },
        {
          "id": "summary-aspiration",
          "type": "text",
          "text": "Aspiration: Fully autonomous reactive UI: changes to Root model auto-trigger visualizations, local ML generates ...",
          "x": 30,
          "y": 530,
          "fill": "#6e7681",
          "font": "10px italic sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T22:47:34.810918"
    },
    "core-panel": {
      "canvas": {
        "width": 1000,
        "height": 600,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "header",
          "type": "rect",
          "x": 10,
          "y": 10,
          "w": 980,
          "h": 50,
          "fill": "#1c2128",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "header-title",
          "type": "text",
          "text": "Core (unknown)",
          "x": 30,
          "y": 35,
          "fill": "#c9d1d9",
          "font": "16px bold sans-serif"
        },
        {
          "id": "status-indicator",
          "type": "rect",
          "x": 960,
          "y": 20,
          "w": 20,
          "h": 30,
          "fill": "#6e7681",
          "stroke": "#6e7681",
          "label": ""
        },
        {
          "id": "summary-bg",
          "type": "rect",
          "x": 10,
          "y": 450,
          "w": 980,
          "h": 140,
          "fill": "#161b22",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "summary-title",
          "type": "text",
          "text": "Subsystem Summary",
          "x": 30,
          "y": 470,
          "fill": "#c9d1d9",
          "font": "12px bold sans-serif"
        },
        {
          "id": "summary-stats",
          "type": "text",
          "text": "Total Modules: 0 | Total Components: 0 | Dependencies: 0",
          "x": 30,
          "y": 500,
          "fill": "#8b949e",
          "font": "11px sans-serif"
        },
        {
          "id": "summary-aspiration",
          "type": "text",
          "text": "Aspiration: Sentient core that continuously monitors system health, predicts issues, auto-heals when possible, c...",
          "x": 30,
          "y": 530,
          "fill": "#6e7681",
          "font": "10px italic sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T22:47:34.823075"
    },
    "canvas-panel": {
      "canvas": {
        "width": 1000,
        "height": 600,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "header",
          "type": "rect",
          "x": 10,
          "y": 10,
          "w": 980,
          "h": 50,
          "fill": "#1c2128",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "header-title",
          "type": "text",
          "text": "Schauspieler Canvas (design)",
          "x": 30,
          "y": 35,
          "fill": "#c9d1d9",
          "font": "16px bold sans-serif"
        },
        {
          "id": "status-indicator",
          "type": "rect",
          "x": 960,
          "y": 20,
          "w": 20,
          "h": 30,
          "fill": "#d29922",
          "stroke": "#d29922",
          "label": ""
        },
        {
          "id": "summary-bg",
          "type": "rect",
          "x": 10,
          "y": 450,
          "w": 980,
          "h": 140,
          "fill": "#161b22",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "summary-title",
          "type": "text",
          "text": "Subsystem Summary",
          "x": 30,
          "y": 470,
          "fill": "#c9d1d9",
          "font": "12px bold sans-serif"
        },
        {
          "id": "summary-stats",
          "type": "text",
          "text": "Total Modules: 0 | Total Components: 0 | Dependencies: 0",
          "x": 30,
          "y": 500,
          "fill": "#8b949e",
          "font": "11px sans-serif"
        },
        {
          "id": "summary-aspiration",
          "type": "text",
          "text": "Aspiration: GPU-powered canvas that autonomously reads model.views, renders in real-time, adapts to hardware cap...",
          "x": 30,
          "y": 530,
          "fill": "#6e7681",
          "font": "10px italic sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T22:47:34.835474"
    },
    "render-api-panel": {
      "canvas": {
        "width": 1000,
        "height": 600,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "header",
          "type": "rect",
          "x": 10,
          "y": 10,
          "w": 980,
          "h": 50,
          "fill": "#1c2128",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "header-title",
          "type": "text",
          "text": "Render Service API (design)",
          "x": 30,
          "y": 35,
          "fill": "#c9d1d9",
          "font": "16px bold sans-serif"
        },
        {
          "id": "status-indicator",
          "type": "rect",
          "x": 960,
          "y": 20,
          "w": 20,
          "h": 30,
          "fill": "#d29922",
          "stroke": "#d29922",
          "label": ""
        },
        {
          "id": "summary-bg",
          "type": "rect",
          "x": 10,
          "y": 450,
          "w": 980,
          "h": 140,
          "fill": "#161b22",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "summary-title",
          "type": "text",
          "text": "Subsystem Summary",
          "x": 30,
          "y": 470,
          "fill": "#c9d1d9",
          "font": "12px bold sans-serif"
        },
        {
          "id": "summary-stats",
          "type": "text",
          "text": "Total Modules: 0 | Total Components: 0 | Dependencies: 0",
          "x": 30,
          "y": 500,
          "fill": "#8b949e",
          "font": "11px sans-serif"
        },
        {
          "id": "summary-aspiration",
          "type": "text",
          "text": "Aspiration: Smart request broker that learns agent patterns, auto-prioritizes important visualization requests, ...",
          "x": 30,
          "y": 530,
          "fill": "#6e7681",
          "font": "10px italic sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T22:47:34.848246"
    },
    "orchestrator-panel": {
      "canvas": {
        "width": 1000,
        "height": 600,
        "background": "#0d1117"
      },
      "elements": [
        {
          "id": "header",
          "type": "rect",
          "x": 10,
          "y": 10,
          "w": 980,
          "h": 50,
          "fill": "#1c2128",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "header-title",
          "type": "text",
          "text": "Display Orchestrator (design)",
          "x": 30,
          "y": 35,
          "fill": "#c9d1d9",
          "font": "16px bold sans-serif"
        },
        {
          "id": "status-indicator",
          "type": "rect",
          "x": 960,
          "y": 20,
          "w": 20,
          "h": 30,
          "fill": "#d29922",
          "stroke": "#d29922",
          "label": ""
        },
        {
          "id": "summary-bg",
          "type": "rect",
          "x": 10,
          "y": 450,
          "w": 980,
          "h": 140,
          "fill": "#161b22",
          "stroke": "#30363d",
          "label": ""
        },
        {
          "id": "summary-title",
          "type": "text",
          "text": "Subsystem Summary",
          "x": 30,
          "y": 470,
          "fill": "#c9d1d9",
          "font": "12px bold sans-serif"
        },
        {
          "id": "summary-stats",
          "type": "text",
          "text": "Total Modules: 0 | Total Components: 0 | Dependencies: 0",
          "x": 30,
          "y": 500,
          "fill": "#8b949e",
          "font": "11px sans-serif"
        },
        {
          "id": "summary-aspiration",
          "type": "text",
          "text": "Aspiration: Intelligent director that learns user focus patterns, anticipates what matters now, composes dynamic...",
          "x": 30,
          "y": 530,
          "fill": "#6e7681",
          "font": "10px italic sans-serif"
        }
      ],
      "styles": {
        "node-reality": {
          "fill": "#238636",
          "stroke": "#ffffff"
        },
        "node-subsystem": {
          "fill": "#3fb950",
          "stroke": "#ffffff"
        },
        "node-module": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "node-aspiration": {
          "fill": "#a371f7",
          "stroke": "#ffffff"
        },
        "node-gap": {
          "fill": "#f85149",
          "stroke": "#ffffff"
        },
        "node-todo": {
          "fill": "#d29922",
          "stroke": "#ffffff"
        },
        "node-concept": {
          "fill": "#58a6ff",
          "stroke": "#ffffff"
        },
        "node-default": {
          "fill": "#6e7681",
          "stroke": "#ffffff"
        },
        "edge-default": {
          "stroke": "#30363d",
          "strokeWidth": 1
        },
        "edge-contains": {
          "stroke": "#30363d",
          "strokeWidth": 2
        },
        "edge-uses": {
          "stroke": "#58a6ff",
          "strokeWidth": 1
        }
      },
      "updated_at": "2026-02-02T22:47:34.861298"
    }
  },
  "node_types": {
    "AgentNode": {
      "description": "A node that is always associated with an agent. Any interaction involving changes inside this node must go through a spawned agent that understands current state and handles the request.",
      "properties": {
        "capabilities": "What this agent node can do (the interface)",
        "spawn_command": "How to spawn the agent for this node",
        "state": "Current state of the agent node",
        "agent_context": "Context given to spawned agents",
        "chat": {
          "description": "Embedded chat for communication with this agent",
          "structure": {
            "messages": "List of {from, text, at} messages",
            "last_read": "Dict of participant -> last read timestamp"
          }
        }
      },
      "behavior": {
        "passive": "Node presents capabilities, agent only spawned when needed",
        "active": "Agent stays running, handles requests continuously"
      },
      "principle": "To change anything INSIDE an AgentNode, you must go through its agent. The agent learns current state, understands the request, thinks, then acts."
    },
    "Template": {
      "description": "A template/guide node that documents how to do something. Not an active node, just documentation.",
      "properties": [
        "steps",
        "required_infrastructure",
        "example_agents"
      ]
    }
  },
  "shapes": {
    "dog": {
      "id": "dog",
      "node_id": "node-dog",
      "bounds": {
        "w": 50,
        "h": 40
      },
      "anchor": {
        "x": 0,
        "y": 0
      },
      "elements": [
        {
          "type": "rect",
          "x": 0,
          "y": 0,
          "w": 50,
          "h": 40,
          "fill": "#ff9800",
          "stroke": "#ffffff",
          "label": "Dog",
          "strokeWidth": 2
        },
        {
          "type": "circle",
          "cx": 35,
          "cy": 15,
          "r": 5,
          "fill": "#000000",
          "stroke": "#ffffff"
        },
        {
          "type": "circle",
          "cx": 10,
          "cy": 30,
          "r": 3,
          "fill": "#ff0000",
          "stroke": "#ffffff"
        }
      ],
      "capabilities": {
        "movable": true,
        "velocity": {
          "x": 5,
          "y": 0
        }
      },
      "state": {},
      "updated_at": "2026-02-02T18:52:08.787189"
    },
    "tree": {
      "id": "tree",
      "node_id": "node-tree",
      "bounds": {
        "w": 55,
        "h": 70
      },
      "anchor": {
        "x": 0,
        "y": 0
      },
      "elements": [
        {
          "type": "rect",
          "x": 20,
          "y": 40,
          "w": 15,
          "h": 30,
          "fill": "#8b4513",
          "stroke": "#654321",
          "strokeWidth": 2
        },
        {
          "type": "circle",
          "cx": 27,
          "cy": 35,
          "r": 25,
          "fill": "#228b22",
          "stroke": "#006400",
          "strokeWidth": 2
        }
      ],
      "capabilities": {
        "collidable": true,
        "solid": true
      },
      "state": {},
      "updated_at": "2026-02-02T18:52:08.792275"
    }
  }
}